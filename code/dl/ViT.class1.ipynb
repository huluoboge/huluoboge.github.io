{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d670ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_ch=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_ch, embed_dim, patch_size, patch_size)\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)                        # (B,embed_dim,H',W')\n",
    "        x = x.flatten(2).transpose(1, 2)        # (B,N,embed_dim)\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, embed_dim=768,\n",
    "                 depth=12, num_heads=12, mlp_ratio=4, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(img_size, patch_size, 3, embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=int(embed_dim * mlp_ratio),\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, depth)\n",
    "\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        B = x.shape[0]\n",
    "\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        cls_out = x[:, 0]\n",
    "        return self.head(cls_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
