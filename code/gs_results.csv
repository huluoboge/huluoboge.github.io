Title,Authors,Published,Summary,arXiv ID,URL
Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations,"Yujia Zhang, Xiaoyang Wu, Yixing Lao, Chengyao Wang, Zhuotao Tian, Naiyan Wang, Hengshuang Zhao",2025-10-27,"Humans learn abstract concepts through multisensory synergy, and once formed, such representations can often be recalled from a single modality. Inspired by this principle, we introduce Concerto, a minimalist simulation of human concept learning for spatial cognition, combining 3D intra-modal self-distillation with 2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more coherent and informative spatial features, as demonstrated by zero-shot visualizations. It outperforms both standalone SOTA 2D and 3D self-supervised models by 14.2% and 4.8%, respectively, as well as their feature concatenation, in linear probing for 3D scene perception. With full fine-tuning, Concerto sets new SOTA results across multiple scene understanding benchmarks (e.g., 80.7% mIoU on ScanNet). We further present a variant of Concerto tailored for video-lifted point cloud spatial understanding, and a translator that linearly projects Concerto representations into CLIP's language space, enabling open-world perception. These results highlight that Concerto emerges spatial representations with superior fine-grained geometric and semantic consistency.",2510.23607v1,http://arxiv.org/abs/2510.23607v1
"Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with Progressive Texture Infilling","Shuhong Zheng, Ashkan Mirzaei, Igor Gilitschenski",2025-10-27,"Current 3D/4D generation methods are usually optimized for photorealism, efficiency, and aesthetics. However, they often fail to preserve the semantic identity of the subject across different viewpoints. Adapting generation methods with one or few images of a specific subject (also known as Personalization or Subject-driven generation) allows generating visual content that align with the identity of the subject. However, personalized 3D/4D generation is still largely underexplored. In this work, we introduce TIRE (Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation. It takes an initial 3D asset produced by an existing 3D generative model as input and uses video tracking to identify the regions that need to be modified. Then, we adopt a subject-driven 2D inpainting model for progressively infilling the identified regions. Finally, we resplat the modified 2D multi-view observations back to 3D while still maintaining consistency. Extensive experiments demonstrate that our approach significantly improves identity preservation in 3D/4D generation compared to state-of-the-art methods. Our project website is available at https://zsh2000.github.io/track-inpaint-resplat.github.io/.",2510.23605v1,http://arxiv.org/abs/2510.23605v1
The Compressed 3D Lyman-Alpha Forest Bispectrum,"Roger de Belsunce, James M. Sullivan, Patrick McDonald",2025-10-27,"Cosmological studies of the Lyman-Alpha (Lya) forest typically constrain parameters using two-point statistics. However, higher-order statistics, such as the three-point function (or its Fourier counterpart, the bispectrum) offer additional information and help break the degeneracy between the mean flux and power spectrum amplitude, albeit at a significant computational cost. To address this, we extend an existing highly informative compression of the bispectrum, the skew spectra, to the Lya forest. We derive the tree-level bispectrum of Lya forest fluctuations in the framework of effective field theory (EFT) directly in redshift space and validate our methodology on synthetic Lya forest data. We measure the anisotropic cross-spectra between the transmitted flux fraction and all quadratic operators arising in the bispectrum, yielding a set of 26 skew spectra. Using idealized 3D Gaussian smoothing (R=10 Mpc/h), we find good agreement (1-2 sigma level based on the statistical errors of the mocks) with the theoretical tree-level bispectrum prediction for monopole and quadrupole up to k <= 0.17 h/Mpc. To enable the cosmological analysis of Lya forest data from the currently observing Dark Energy Spectroscopic Instrument (DESI), where we cannot do 3D smoothing, we use a line-of-sight smoothing and introduce a new statistic, the shifted skew spectra. These probe non-squeezed bispectrum triangles and avoid locally applying quadratic operators to the field by displacing one copy of the field in the radial direction. Using a fixed displacement of 40 Mpc/h (and line-of-sight smoothing of 10 Mpc/h) yields a similar agreement with the theory prediction. For the special case of correlating the squared (and displaced) field with the original one, we analytically forward model the window function making this approach readily applicable to DESI data.",2510.23597v1,http://arxiv.org/abs/2510.23597v1
Gaussian tomography for cold-atom simulators,"Matthew Kiser, Max McGinley, Daniel Malz",2025-10-27,"A limitation of analog quantum simulators based on cold atoms in optical lattices is that readout is typically limited to observables diagonal in the charge basis, i.e., densities and density correlation functions. To overcome this limitation, we propose experiment-friendly schemes to measure charge-off-diagonal correlations (such as currents). Our protocols use non-interacting dynamics for random times followed by standard quantum gas microscope measurements to effectively measure in random bases. The main requirement of our scheme is the ability to turn off interactions, which can be done in many atomic species using Feshbach resonances. Importantly, our scheme requires no local control and otherwise also exhibits modest requirements in terms of total evolution time and number of repetitions. We numerically demonstrate efficient estimation of bilinear correlation functions, requiring less than $4000$ samples to measure local currents to 5% error (system-size independent) and $\sim 10^4$ samples to simultaneously measure all non-local correlations in 70-site systems. Due to its simplicity, our protocol is implementable in existing platforms and thus paves the way to precision measurements beyond particle number measurements.",2510.23591v1,http://arxiv.org/abs/2510.23591v1
InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video Cameras,"Erich Liang, Roma Bhattacharjee, Sreemanti Dey, Rafael Moschopoulos, Caitlin Wang, Michel Liao, Grace Tan, Andrew Wang, Karhan Kayan, Stamatis Alexandropoulos, Jia Deng",2025-10-27,"Accurately tracking camera intrinsics is crucial for achieving 3D understanding from 2D video. However, most 3D algorithms assume that camera intrinsics stay constant throughout a video, which is often not true for many real-world in-the-wild videos. A major obstacle in this field is a lack of dynamic camera intrinsics benchmarks--existing benchmarks typically offer limited diversity in scene content and intrinsics variation, and none provide per-frame intrinsic changes for consecutive video frames. In this paper, we present Intrinsics in Flux (InFlux), a real-world benchmark that provides per-frame ground truth intrinsics annotations for videos with dynamic intrinsics. Compared to prior benchmarks, InFlux captures a wider range of intrinsic variations and scene diversity, featuring 143K+ annotated frames from 386 high-resolution indoor and outdoor videos with dynamic camera intrinsics. To ensure accurate per-frame intrinsics, we build a comprehensive lookup table of calibration experiments and extend the Kalibr toolbox to improve its accuracy and robustness. Using our benchmark, we evaluate existing baseline methods for predicting camera intrinsics and find that most struggle to achieve accurate predictions on videos with dynamic intrinsics. For the dataset, code, videos, and submission, please visit https://influx.cs.princeton.edu/.",2510.23589v1,http://arxiv.org/abs/2510.23589v1
RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation,"Yash Jangir, Yidi Zhang, Kashu Yamazaki, Chenyu Zhang, Kuan-Hsun Tu, Tsung-Wei Ke, Lei Ke, Yonatan Bisk, Katerina Fragkiadaki",2025-10-27,"The pursuit of robot generalists - instructable agents capable of performing diverse tasks across diverse environments - demands rigorous and scalable evaluation. Yet real-world testing of robot policies remains fundamentally constrained: it is labor-intensive, slow, unsafe at scale, and difficult to reproduce. Existing simulation benchmarks are similarly limited, as they train and test policies within the same synthetic domains and cannot assess models trained from real-world demonstrations or alternative simulation environments. As policies expand in scope and complexity, these barriers only intensify, since defining ""success"" in robotics often hinges on nuanced human judgments of execution quality. In this paper, we introduce a new benchmarking framework that overcomes these challenges by shifting VLA evaluation into large-scale simulated environments augmented with online human feedback. Leveraging advances in vision-language models, 2D-to-3D generative modeling, and differentiable rendering, our approach automatically converts video demonstrations from widely used robot datasets into simulated counterparts. Within these digital twins, we assess VLA policies using both automated VLM-guided scoring and scalable human preference judgments collected from crowdworkers, transforming human involvement from tedious scene setup, resetting, and safety supervision into lightweight preference comparisons. To measure robustness, we systematically perturb simulated environments along multiple axes, such as textures and object placements, stress-testing policy generalization under controlled variation. The result is a continuously evolving, reproducible, and scalable benchmark for real-world trained robot manipulation policies, addressing a critical missing capability in today's robotics landscape.",2510.23571v1,http://arxiv.org/abs/2510.23571v1
Tests of independence for pairs of paths of non-stationary Gaussian processes,"Philip A. Ernst, Frederi G. Viens, Shuo Yan",2025-10-27,"In the current work, we provide theoretical results for testing (in)dependence between pairs of paths of most commonly studied non-stationary Gaussian processes - standard Brownian motion and fractional Brownian motion (fBm). Please see the PDF version of the paper for a full abstract.",2510.23563v1,http://arxiv.org/abs/2510.23563v1
Bayesian Nonlinear PDE Inference via Gaussian Process Collocation with Application to the Richards Equation,"Yumo Yang, Anass Ben Bouazza, Xuejun Dong, Quan Zhou",2025-10-27,"The estimation of unknown parameters in nonlinear partial differential equations (PDEs) offers valuable insights across a wide range of scientific domains. In this work, we focus on estimating plant root parameters in the Richards equation, which is essential for understanding the soil-plant system in agricultural studies. Since conventional methods are computationally intensive and often yield unstable estimates, we develop a new Gaussian process collocation method for efficient Bayesian inference. Unlike existing Gaussian process-based approaches, our method constructs an approximate posterior distribution using samples drawn from a Gaussian process model fitted to the observed data, which does not require any structural assumption about the underlying PDE. Further, we propose to use an importance sampling procedure to correct for the discrepancy between the approximate and true posterior distributions. As an alternative, we also devise a prior-guided Bayesian optimization algorithm leveraging the approximate posterior. Simulation studies demonstrate that our method yields robust estimates under various settings. Finally, we apply our method on a real agricultural data set and estimate the plant root parameters with uncertainty quantification.",2510.23550v1,http://arxiv.org/abs/2510.23550v1
DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised Domain Adaptation in 3D LiDAR Semantic Segmentation,"Wanmeng Li, Simone Mosco, Daniel Fusaro, Alberto Pretto",2025-10-27,"Annotating real-world LiDAR point clouds for use in intelligent autonomous systems is costly. To overcome this limitation, self-training-based Unsupervised Domain Adaptation (UDA) has been widely used to improve point cloud semantic segmentation by leveraging synthetic point cloud data. However, we argue that existing methods do not effectively utilize unlabeled data, as they either rely on predefined or fixed confidence thresholds, resulting in suboptimal performance. In this paper, we propose a Dynamic Pseudo-Label Filtering (DPLF) scheme to enhance real data utilization in point cloud UDA semantic segmentation. Additionally, we design a simple and efficient Prior-Guided Data Augmentation Pipeline (PG-DAP) to mitigate domain shift between synthetic and real-world point clouds. Finally, we utilize data mixing consistency loss to push the model to learn context-free representations. We implement and thoroughly evaluate our approach through extensive comparisons with state-of-the-art methods. Experiments on two challenging synthetic-to-real point cloud semantic segmentation tasks demonstrate that our approach achieves superior performance. Ablation studies confirm the effectiveness of the DPLF and PG-DAP modules. We release the code of our method in this paper.",2510.23525v1,http://arxiv.org/abs/2510.23525v1
Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation,"Anthony Opipari, Aravindhan K Krishnan, Shreekant Gayaka, Min Sun, Cheng-Hao Kuo, Arnie Sen, Odest Chadwicke Jenkins",2025-10-27,"Remembering where object segments were predicted in the past is useful for improving the accuracy and consistency of class-agnostic video segmentation algorithms. Existing video segmentation algorithms typically use either no object-level memory (e.g. FastSAM) or they use implicit memories in the form of recurrent neural network features (e.g. SAM2). In this paper, we augment both types of segmentation models using an explicit 3D memory and show that the resulting models have more accurate and consistent predictions. For this, we develop an online 3D Gaussian Splatting (3DGS) technique to store predicted object-level segments generated throughout the duration of a video. Based on this 3DGS representation, a set of fusion techniques are developed, named FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve their respective foundation models' predictions. Ablation experiments are used to validate the proposed techniques' design and hyperparameter settings. Results from both real-world and simulated benchmarking experiments show that models which use explicit 3D memories result in more accurate and consistent predictions than those which use no memory or only implicit neural network memories. Project Page: https://topipari.com/projects/FastSAM-Splat/",2510.23521v1,http://arxiv.org/abs/2510.23521v1
Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap,"Elisabeth Jüttner, Leona Krath, Stefan Korfhage, Hannah Dröge, Matthias B. Hullin, Markus Plack",2025-10-27,"Volumetric video relighting is essential for bringing captured performances into virtual worlds, but current approaches struggle to deliver temporally stable, production-ready results. Diffusion-based intrinsic decomposition methods show promise for single frames, yet suffer from stochastic noise and instability when extended to sequences, while video diffusion models remain constrained by memory and scale. We propose a hybrid relighting framework that combines diffusion-derived material priors with temporal regularization and physically motivated rendering. Our method aggregates multiple stochastic estimates of per-frame material properties into temporally consistent shading components, using optical-flow-guided regularization. For indirect effects such as shadows and reflections, we extract a mesh proxy from Gaussian Opacity Fields and render it within a standard graphics pipeline. Experiments on real and synthetic captures show that this hybrid strategy achieves substantially more stable relighting across sequences than diffusion-only baselines, while scaling beyond the clip lengths feasible for video diffusion. These results indicate that hybrid approaches, which balance learned priors with physically grounded constraints, are a practical step toward production-ready volumetric video relighting.",2510.23494v1,http://arxiv.org/abs/2510.23494v1
"UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception","Karthikeyan Chandra Sekaran, Markus Geisler, Dominik Rößle, Adithya Mohan, Daniel Cremers, Wolfgang Utschick, Michael Botsch, Werner Huber, Torsten Schön",2025-10-27,"Recent cooperative perception datasets have played a crucial role in advancing smart mobility applications by enabling information exchange between intelligent agents, helping to overcome challenges such as occlusions and improving overall scene understanding. While some existing real-world datasets incorporate both vehicle-to-vehicle and vehicle-to-infrastructure interactions, they are typically limited to a single intersection or a single vehicle. A comprehensive perception dataset featuring multiple connected vehicles and infrastructure sensors across several intersections remains unavailable, limiting the benchmarking of algorithms in diverse traffic environments. Consequently, overfitting can occur, and models may demonstrate misleadingly high performance due to similar intersection layouts and traffic participant behavior. To address this gap, we introduce UrbanIng-V2X, the first large-scale, multi-modal dataset supporting cooperative perception involving vehicles and infrastructure sensors deployed across three urban intersections in Ingolstadt, Germany. UrbanIng-V2X consists of 34 temporally aligned and spatially calibrated sensor sequences, each lasting 20 seconds. All sequences contain recordings from one of three intersections, involving two vehicles and up to three infrastructure-mounted sensor poles operating in coordinated scenarios. In total, UrbanIng-V2X provides data from 12 vehicle-mounted RGB cameras, 2 vehicle LiDARs, 17 infrastructure thermal cameras, and 12 infrastructure LiDARs. All sequences are annotated at a frequency of 10 Hz with 3D bounding boxes spanning 13 object classes, resulting in approximately 712k annotated instances across the dataset. We provide comprehensive evaluations using state-of-the-art cooperative perception methods and publicly release the codebase, dataset, HD map, and a digital twin of the complete data collection environment.",2510.23478v1,http://arxiv.org/abs/2510.23478v1
Trajectory-Aware Air-to-Ground Channel Characterization for Low-Altitude UAVs Using MaMIMO Measurements,"Abdul Saboor, Zhuangzhuang Cui, Achiel Colpaert, Evgenii Vinogradov, Wout Joseph, Sofie Pollin",2025-10-27,"This paper presents a comprehensive measurement-based trajectory-aware characterization of low-altitude Air-to-Ground (A2G) channels in a suburban environment. A 64-element Massive Multi-Input Multi-Output (MaMIMO) array was used to capture channels for three trajectories of an Uncrewed Aerial Vehicle (UAV), including two horizontal zig-zag flights at fixed altitudes and one vertical ascent, chosen to emulate AUE operations and to induce controlled azimuth and elevation sweeps for analyzing geometry-dependent propagation dynamics. We examine large-scale power variations and their correlation with geometric features, such as elevation, azimuth, and 3D distance, followed by an analysis of fading behavior through distribution fitting and Rician K-factor estimation. Furthermore, temporal non-stationarity is quantified using the Correlation Matrix Distance (CMD), and angular stationarity spans are utilized to demonstrate how channel characteristics change with the movement of the UAV. We also analyze Spectral Efficiency (SE) in relation to K-factor and Root Mean Square (RMS) delay spread, highlighting their combined influence on link performance. The results show that the elevation angle is the strongest predictor of the received power, with a correlation of more than 0.77 for each trajectory, while the Nakagami model best fits the small-scale fading. The K-factor increases from approximately 5 dB at low altitudes to over 15 dB at higher elevations, indicating stronger LoS dominance. Non-stationarity patterns are highly trajectory- and geometry-dependent, with azimuth most affected in horizontal flights and elevation during vertical flight. These findings offer valuable insights for modeling and improving UAV communication channels in 6G Non-Terrestrial Networks (NTNs).",2510.23465v1,http://arxiv.org/abs/2510.23465v1
Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences,"Zhuoran Jin, Hongbang Yuan, Kejian Zhu, Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",2025-10-27,"Reward models (RMs) play a critical role in aligning AI behaviors with human preferences, yet they face two fundamental challenges: (1) Modality Imbalance, where most RMs are mainly focused on text and image modalities, offering limited support for video, audio, and other modalities; and (2) Preference Rigidity, where training on fixed binary preference pairs fails to capture the complexity and diversity of personalized preferences. To address the above challenges, we propose Omni-Reward, a step toward generalist omni-modal reward modeling with support for free-form preferences, consisting of: (1) Evaluation: We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form preferences, covering nine tasks across five modalities including text, image, video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal preference dataset comprising 248K general preference pairs and 69K instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We propose Omni-RewardModel, which includes both discriminative and generative RMs, and achieves strong performance on Omni-RewardBench as well as other widely used reward modeling benchmarks.",2510.23451v1,http://arxiv.org/abs/2510.23451v1
A Physics-Informed Variational Inference Framework for Identifying Attributions of Extreme Stress Events in Low-Grain Polycrystals,"Yinling Zhang, Samuel D. Dunham, Curt A. Bronkhorst, Nan Chen",2025-10-27,"Polycrystalline metal failure often begins with stress concentration at grain boundaries. Identifying which microstructural features trigger these events is important but challenging because these extreme damage events are rare and the failure mechanisms involve multiple complex processes across scales. Most existing inference methods focus on average behavior rather than rare events, whereas standard sample-based methods are computationally expensive for high-dimensional complex systems. In this paper, we develop a new variational inference framework that integrates a recently developed computationally efficient physics-informed statistical model with extreme value statistics to significantly facilitate the identification of material failure attributions. First, we reformulate the objective to emphasize observed exceedances by incorporating extreme-value theory into the likelihood, thereby highlighting tail behavior. Second, we constrain inference via a physics-informed statistical model that characterizes microstructure-stress relationships, which uniquely provides physically consistent predictions for these rare events. Third, mixture models in a reduced latent space are developed to capture the non-Gaussian characteristics of microstructural features, allowing the identification of multiple underlying mechanisms. In both controlled and realistic experimental tests for the bicrystal configuration, the framework achieves reliable extreme-event prediction and reveals the microstructural features associated with material failure, providing physical insights for material design with uncertainty quantification.",2510.23437v1,http://arxiv.org/abs/2510.23437v1
MiCADangelo: Fine-Grained Reconstruction of Constrained CAD Models from 3D Scans,"Ahmet Serdar Karadeniz, Dimitrios Mallis, Danila Rukhovich, Kseniya Cherenkova, Anis Kacem, Djamila Aouada",2025-10-27,"Computer-Aided Design (CAD) plays a foundational role in modern manufacturing and product development, often requiring designers to modify or build upon existing models. Converting 3D scans into parametric CAD representations--a process known as CAD reverse engineering--remains a significant challenge due to the high precision and structural complexity of CAD models. Existing deep learning-based approaches typically fall into two categories: bottom-up, geometry-driven methods, which often fail to produce fully parametric outputs, and top-down strategies, which tend to overlook fine-grained geometric details. Moreover, current methods neglect an essential aspect of CAD modeling: sketch-level constraints. In this work, we introduce a novel approach to CAD reverse engineering inspired by how human designers manually perform the task. Our method leverages multi-plane cross-sections to extract 2D patterns and capture fine parametric details more effectively. It enables the reconstruction of detailed and editable CAD models, outperforming state-of-the-art methods and, for the first time, incorporating sketch constraints directly into the reconstruction process.",2510.23429v1,http://arxiv.org/abs/2510.23429v1
A grad-curl conforming virtual element method for a grad-curl problem linking the 3D quad-curl problem and Stokes system,"Xiaojing Dong, Yibing Han, Yunqing Huang",2025-10-27,"Based on the Stokes complex with vanishing boundary conditions and its dual complex, we reinterpret a grad-curl problem arising from the quad-curl problem as a new vector potential formulation of the three-dimensional Stokes system. By extending the analysis to the corresponding non-homogeneous problems and the accompanying trace complex, we construct a novel $\boldsymbol{H}(\operatorname{grad-curl})$-conforming virtual element space with arbitrary approximation order that satisfies the exactness of the associated discrete Stokes complex. In the lowest-order case, three degrees of freedom are assigned to each vertex and one to each edge. For the grad-curl problem, we rigorously establish the interpolation error estimates, the stability of discrete bilinear forms, and the convergence of the proposed element on polyhedral meshes. As a discrete vector potential formulation of the Stokes problem, the resulting system is pressure-decoupled and symmetric positive definite. Some numerical examples are presented to verify the theoretical results.",2510.23425v1,http://arxiv.org/abs/2510.23425v1
Quality-controlled registration of urban MLS point clouds reducing drift effects by adaptive fragmentation,"Marco Antonio Ortiz Rincon, Yihui Yang, Christoph Holst",2025-10-27,"This study presents a novel workflow designed to efficiently and accurately register large-scale mobile laser scanning (MLS) point clouds to a target model point cloud in urban street scenarios. This workflow specifically targets the complexities inherent in urban environments and adeptly addresses the challenges of integrating point clouds that vary in density, noise characteristics, and occlusion scenarios, which are common in bustling city centers. Two methodological advancements are introduced. First, the proposed Semi-sphere Check (SSC) preprocessing technique optimally fragments MLS trajectory data by identifying mutually orthogonal planar surfaces. This step reduces the impact of MLS drift on the accuracy of the entire point cloud registration, while ensuring sufficient geometric features within each fragment to avoid local minima. Second, we propose Planar Voxel-based Generalized Iterative Closest Point (PV-GICP), a fine registration method that selectively utilizes planar surfaces within voxel partitions. This pre-process strategy not only improves registration accuracy but also reduces computation time by more than 50% compared to conventional point-to-plane ICP methods. Experiments on real-world datasets from Munich's inner city demonstrate that our workflow achieves sub-0.01 m average registration accuracy while significantly shortening processing times. The results underscore the potential of the proposed methods to advance automated 3D urban modeling and updating, with direct applications in urban planning, infrastructure management, and dynamic city monitoring.",2510.23416v1,http://arxiv.org/abs/2510.23416v1
Towards Generalisable Foundation Models for 3D Brain MRI,"Moona Mazher, Geoff J. M. Parker, Daniel C. Alexander",2025-10-27,"Foundation models in artificial intelligence (AI) are transforming medical imaging by enabling general-purpose feature learning from large-scale, unlabeled datasets. In this work, we introduce BrainFound, a self-supervised foundation model for brain MRI, built by extending DINO-v2, a vision transformer originally designed for 2D natural images. BrainFound adapts DINO-v2 to model full 3D brain anatomy by incorporating volumetric information from sequential MRI slices, moving beyond conventional single-slice paradigms. It supports both single- and multimodal inputs, enabling a broad range of downstream tasks, including disease detection and image segmentation, while generalising across varied imaging protocols and clinical scenarios. We show that BrainFound consistently outperforms existing self-supervised pretraining strategies and supervised baselines, particularly in label-scarce and multi-contrast settings. By integrating information from diverse 3D MRI modalities (e.g., T1, T2, FLAIR), it enhances diagnostic accuracy and reduces dependency on extensive expert annotations. This flexibility makes BrainFound a scalable and practical solution for 3D neuroimaging pipelines, with significant potential for clinical deployment and research innovation.",2510.23415v1,http://arxiv.org/abs/2510.23415v1
Free-space quantum interface of a single atomic tweezer array with light,"Yakov Solomons, Roni Ben-Maimon, Arpit Behera, Ofer Firstenberg, Nir Davidson, Ephraim Shahmoon",2025-10-27,"We present a practical approach for interfacing light with a two-dimensional atomic tweezer array. Typical paraxial fields are poorly matched to the array's multi-diffraction-order radiation pattern, thus severely limiting the interface coupling efficiency. Instead, we propose to design a field mode that naturally couples to the array: it consists of a unique superposition of multiple beams corresponding to the array's diffraction orders. This composite mode can be generated from a single Gaussian beam using standard free-space optics, including spatial light modulators and a single objective lens. For a triangular array with lattice spacing about twice the wavelength, all diffraction angles remain below 35 degrees, making the scheme compatible with standard objectives of numerical aperture NA <= 0.7. Our analytical theory and scattering simulations reveal that the interface efficiency r0 for quantum information tasks scales favorably with the array atom number N: reaching >0.99 (>0.9999) for N = 149 (N approximately 1000) and scaling as 1 - r0 scales as 1/N for large N. The scheme is robust to optical imperfections and atomic-position errors, offering a viable path for quantum light-matter applications and state readout in current tweezer-array platforms.",2510.23398v1,http://arxiv.org/abs/2510.23398v1
Investigation of Resonances in the $Σ({1/2}^{-})$ System Based on the Chiral Quark Model,"Yu Yao, Xuejie Liu, Xiaoyun Chen, Yuheng Wu, Jialun Ping, Yue Tan, Qi Huang",2025-10-27,"In this work, we investigate the resonance structures in the $\Sigma(1/2^-)$ system from both three-quark and five-quark perspectives within the framework of the chiral quark model. An accurate few-body computational approach, the Gaussian Expansion Method, is employed to construct the orbital wave functions of multiquark states. To reduce the model dependence on parameters, we fit two sets of parameters to check the stability of the results. The calculations show that our results remain stable despite changes in the parameters. In the three-quark calculations, two $\Sigma(1/2^-)$ states are obtained with energies around 1.8~GeV, which are good candidates for the experimentally observed $\Sigma(1750)$ and $\Sigma(1900)$. In the five-quark configuration, several stable resonance states are identified, including $\Sigma \pi$, $N \bar{K}$, and $N \bar{K}^{*}$. These resonance states survive the channel-coupling calculations under the complex-scaling framework and manifest as stable structures. Our results support the existence of a two-pole structure for the $\Sigma(1/2^-)$ system, predominantly composed of $\Sigma \pi$ and $N \bar{K}$ configurations, analogous to the well-known $\Lambda(1380)$-$\Lambda(1405)$ ($\Sigma \pi$-$N \bar{K}$) system. On the other hand, although the energy of the $N \bar{K}^{*}$ configuration is close to that of $\Sigma(1750)$ and $\Sigma(1900)$, the obtained width is not consistent with the experimental values. This suggests that the $N \bar{K}^{*}$ state needs to mix with three-quark components to better explain the experimental $\Sigma(1750)$ and $\Sigma(1900)$ states. According to our decay width calculations, the predicted two resonance states are primarily composed of $\Sigma \pi$ and $N \bar{K}$, with their main decay channel being $\Lambda \pi$.",2510.23378v1,http://arxiv.org/abs/2510.23378v1
Primordial Non-Gaussianity from a String-Inspired Cosmology,M. Meo,2025-10-27,"The interplay between string theory and early-universe cosmology offers promising avenues to explore high-energy regimes where the standard single-field slow-roll model may no longer provide an accurate description. One intriguing scenario emerges from certain non-supersymmetric string models, where supersymmetry breaking induces a non-trivial vacuum energy, or more precisely an exponential potential for scalar fields, and primarily for the dilaton. This setup gives rise to the so-called ""climbing scalar"" phenomenon, whereby the scalar is forced to emerge from the initial singularity while climbing up the potential, if sufficiently steep. This phase precedes a turning point, and the subsequent descent can support inflation. The resulting pre-inflationary dynamics can leave imprints in cosmological observables. To begin with, it induces a low-frequency cut in the primordial power spectrum that resonates with the lack of power present in the first few CMB multipoles. The main theme of this work is to clarify its possible effect on non-Gaussianities.",2510.23377v1,http://arxiv.org/abs/2510.23377v1
Ground-state phase diagram of S = 1/2 Heisenberg model on 2D square-hexagon-octagon lattice,"Yumeng Luo, Yuehong Li, Mengfan Jiang, Muwei Wu, Jian-Jian Yang, Dao-Xin Yao, Han-Qing Wu",2025-10-27,"Using stochastic series expansion quantum Monte Carlo method and density matrix renormalization group, we study the ground-state phase diagram of $S=1/2$ Heisenberg model on 2D square-hexagon-octagon (SHO) lattice. In this model, we consider two kinds of nearest-neighbor interaction (intra-hexagon interaction $J_1$ and inter-hexagon $J_2$) and the selected third nearest-neighbor interaction $J_3$ along $x$ direction. From our calculations, there are five phases in the parameters regime $0<\lambda_1=J_2/J_1<4, 0<\lambda_2=J_3/J_1<4$, including a N\'eel antiferromagentic phase, a Haldane-like symmetry protected topological phase, a hexagon phase and two dimer phases. In the Haldane-like SPT phase, we characterized its topological nature using the degeneracy of ground-state energy under open boundary condition and the entanglement spectrum. To characterize the phase boundaries, we use spin stiffness and Binder cumulant to do the comprehensive finite-size scalings. From data collapse, the critical behaviors of all the nonmagnetic phases to the antiferromagnetic phase belong to the 3D $O(3)$ Heisenberg universality class. As a theoretical exploration, our work establishes a foundational framework for understanding 2D magnetism on the SHO lattice.",2510.23376v1,http://arxiv.org/abs/2510.23376v1
"Quadratic Truncated Random Return in Distributional LQR: Positive Definiteness, Density, and Log-Concavity","Ruyi Teng, Dan Wang, Wei Chen, Yulong Gao",2025-10-27,"Distributional linear quadratic regulator (LQR) is a new framework that integrates the distributional reinforcement learning and classical LQR, which offers a new way to study the random return instead of the expected cost. Unlike iterative approximation using dynamic programming in the DRL, a closed-form expression for the random return can be exactly characterized in the distributional LQR, which is defined over infinitely many random variables. In recent work [1, 2], it has been shown that this random return can be well approximated by a finite number of random variables, which we call truncated random return. In this paper, we study the truncated random return in the distributional LQR. We show that the truncated random return can be naturally expressed in the quadratic form. We develop a sufficient condition for the positive definiteness of the block symmetric matrix in the quadratic form and provide the lower and upper bounds on the eigenvalues of this matrix. We further show that in this case, the truncated random return follows a positively weighted non-central chi-square distribution if the random disturbances admits Gaussian, and its cumulative distribution function is log-concave if the probability density function of the random disturbances is log-concave.",2510.23332v1,http://arxiv.org/abs/2510.23332v1
Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon,"Shreya Santra, Thomas Robbins, Kazuya Yoshida",2025-10-27,"Autonomous navigation in unstructured environments is essential for field and planetary robotics, where robots must efficiently reach goals while avoiding obstacles under uncertain conditions. Conventional algorithmic approaches often require extensive environment-specific tuning, limiting scalability to new domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative, allowing robots to acquire navigation strategies through direct interactions with their environment. This work investigates the feasibility of DRL policy generalization across visually and topographically distinct simulated domains, where policies are trained in terrestrial settings and validated in a zero-shot manner in extraterrestrial environments. A 3D simulation of an agricultural rover is developed and trained using Proximal Policy Optimization (PPO) to achieve goal-directed navigation and obstacle avoidance in farmland settings. The learned policy is then evaluated in a lunar-like simulated environment to assess transfer performance. The results indicate that policies trained under terrestrial conditions retain a high level of effectiveness, achieving close to 50\% success in lunar simulations without the need for additional training and fine-tuning. This underscores the potential of cross-domain DRL-based policy transfer as a promising approach to developing adaptable and efficient autonomous navigation for future planetary exploration missions, with the added benefit of minimizing retraining costs.",2510.23329v1,http://arxiv.org/abs/2510.23329v1
Multitask Multimodal Self-Supervised Learning for Medical Images,Cristian Simionescu,2025-10-27,"This thesis works to address a pivotal challenge in medical image analysis: the reliance on extensive labeled datasets, which are often limited due to the need for expert annotation and constrained by privacy and legal issues. By focusing on the development of self-supervised learning techniques and domain adaptation methods, this research aims to circumvent these limitations, presenting a novel approach to enhance the utility and efficacy of deep learning in medical imaging.   Central to this thesis is the development of the Medformer, an innovative neural network architecture designed for multitask learning and deep domain adaptation. This model is adept at pre-training on diverse medical image datasets, handling varying sizes and modalities, and is equipped with a dynamic input-output adaptation mechanism. This enables efficient processing and integration of a wide range of medical image types, from 2D X-rays to complex 3D MRIs, thus mitigating the dependency on large labeled datasets.   Further, the thesis explores the current state of self-supervised learning in medical imaging. It introduces novel pretext tasks that are capable of extracting meaningful information from unlabeled data, significantly advancing the model's interpretative abilities. This approach is validated through rigorous experimentation, including the use of the MedMNIST dataset, demonstrating the model's proficiency in learning generalized features applicable to various downstream tasks.   In summary, this thesis contributes to the advancement of medical image analysis by offering a scalable, adaptable framework that reduces reliance on labeled data. It paves the way for more accurate, efficient diagnostic tools in healthcare, signifying a major step forward in the application of deep learning in medical imaging.",2510.23325v1,http://arxiv.org/abs/2510.23325v1
ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via Generation,"Jiahao Chang, Chongjie Ye, Yushuang Wu, Yuantao Chen, Yidan Zhang, Zhongjin Luo, Chenghong Li, Yihao Zhi, Xiaoguang Han",2025-10-27,"Existing multi-view 3D object reconstruction methods heavily rely on sufficient overlap between input views, where occlusions and sparse coverage in practice frequently yield severe reconstruction incompleteness. Recent advancements in diffusion-based 3D generative techniques offer the potential to address these limitations by leveraging learned generative priors to hallucinate invisible parts of objects, thereby generating plausible 3D structures. However, the stochastic nature of the inference process limits the accuracy and reliability of generation results, preventing existing reconstruction frameworks from integrating such 3D generative priors. In this work, we comprehensively analyze the reasons why diffusion-based 3D generative methods fail to achieve high consistency, including (a) the insufficiency in constructing and leveraging cross-view connections when extracting multi-view image features as conditions, and (b) the poor controllability of iterative denoising during local detail generation, which easily leads to plausible but inconsistent fine geometric and texture details with inputs. Accordingly, we propose ReconViaGen to innovatively integrate reconstruction priors into the generative framework and devise several strategies that effectively address these issues. Extensive experiments demonstrate that our ReconViaGen can reconstruct complete and accurate 3D models consistent with input views in both global structure and local details.Project page: https://jiahao620.github.io/reconviagen.",2510.23306v1,http://arxiv.org/abs/2510.23306v1
CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach,"Riccardo Romanello, Daniele Lizzio Bosco, Jacopo Cossio, Dusan Sutulovic, Giuseppe Serra, Carla Piazza, Paolo Burelli",2025-10-27,"CNOT gates are fundamental to quantum computing, as they facilitate entanglement, a crucial resource for quantum algorithms. Certain classes of quantum circuits are constructed exclusively from CNOT gates. Given their widespread use, it is imperative to minimise the number of CNOT gates employed. This problem, known as CNOT minimisation, remains an open challenge, with its computational complexity yet to be fully characterised. In this work, we introduce a novel reinforcement learning approach to address this task. Instead of training multiple reinforcement learning agents for different circuit sizes, we use a single agent up to a fixed size $m$. Matrices of sizes different from m are preprocessed using either embedding or Gaussian striping. To assess the efficacy of our approach, we trained an agent with m = 8, and evaluated it on matrices of size n that range from 3 to 15. The results we obtained show that our method overperforms the state-of-the-art algorithm as the value of n increases.",2510.23304v1,http://arxiv.org/abs/2510.23304v1
Learning from Frustration: Torsor CNNs on Graphs,"Daiyuan Li, Shreya Arya, Robert Ghrist",2025-10-27,"Most equivariant neural networks rely on a single global symmetry, limiting their use in domains where symmetries are instead local. We introduce Torsor CNNs, a framework for learning on graphs with local symmetries encoded as edge potentials-- group-valued transformations between neighboring coordinate frames. We establish that this geometric construction is fundamentally equivalent to the classical group synchronization problem, yielding: (1) a Torsor Convolutional Layer that is provably equivariant to local changes in coordinate frames, and (2) the frustration loss--a standalone geometric regularizer that encourages locally equivariant representations when added to any NN's training objective. The Torsor CNN framework unifies and generalizes several architectures--including classical CNNs and Gauge CNNs on manifolds-- by operating on arbitrary graphs without requiring a global coordinate system or smooth manifold structure. We establish the mathematical foundations of this framework and demonstrate its applicability to multi-view 3D recognition, where relative camera poses naturally define the required edge potentials.",2510.23288v1,http://arxiv.org/abs/2510.23288v1
Generalized Strichartz estimates for the massive Dirac equation with critical potentials,"Federico Cacciafesta, Elena Danesi, Eric Séré",2025-10-27,"In this paper we prove generalized Strichartz estimates for the massive Dirac equation in the case of two critical potential perturbations, namely the $2d$ Aharonov-Bohm magnetic potential and the $3d$ Coulomb potential. The proof makes use of the relativistic Hankel transform introduced in previous works of Cacciafesta, S\'er\'e and Cacciafesta, Fanelli for the massless systems, and here adapted to the massive case: this allows for an explicit representation of the solutions, which reduces the analysis to the proof of suitable estimates on the generalized eigenfunctions of the operators. To the best of our knowledge, these are the first dispersive estimates for the massive Dirac equation with critical potentials.",2510.23283v1,http://arxiv.org/abs/2510.23283v1
Energetics of star-planet magnetic interactions: Novel insights from 3D modelling,"Arghyadeep Paul, Antoine Strugarek",2025-10-27,"Star-planet magnetic interactions (SPMI) occurring in the sub-Alfvenic regime can, in principle, induce stellar chromospheric hotspots. Currently, estimates of the power generated by SPMI primarily rely on analytical scaling laws that relate stellar and planetary parameters to the interaction energetics. The existing scaling laws published in the literature so far do not agree with each other by at least an order of magnitude. Our aim is to quantify an absolute upper limit on the power that a planet can channel back to its host star during such interactions, which in turn lead to the formation of stellar hotspots. By performing a series of 3D MHD simulations with varied parameters known to influence the energetics of SPMI, we derive a numerically supported scaling law that can be used to reliably estimate the energy channeled from the planet back to the star. Our results suggest that existing analytical scaling laws may not fully capture the power transferred from the planet to the star through SPMI. The scaling law derived from our numerical simulations appears to provide a more comprehensive estimate, reflecting dependencies on common stellar and planetary parameters also considered in earlier models. Moreover, our findings indicate that power generation involves not only the planetary obstacle itself but also the extended magnetic structure of the Alfven wings interacting with the streaming stellar wind. This study suggests that care should be taken when applying analogies directly from jovian sub-Alfvenic interactions to SPMI, as the underlying physical conditions (specifically the value of the Alfvenic Mach number) may not be directly comparable. Our numerically derived scaling law offers a potentially improved approach for estimating SPMI power, capturing some of the interaction's complexities exclusive to SPMI.",2510.23277v1,http://arxiv.org/abs/2510.23277v1
Privacy-Preserving Semantic Communication over Wiretap Channels with Learnable Differential Privacy,"Weixuan Chen, Qianqian Yang, Shuo Shao, Shunpu Tang, Zhiguo Shi, Shui Yu",2025-10-27,"While semantic communication (SemCom) improves transmission efficiency by focusing on task-relevant information, it also raises critical privacy concerns. Many existing secure SemCom approaches rely on restrictive or impractical assumptions, such as favorable channel conditions for the legitimate user or prior knowledge of the eavesdropper's model. To address these limitations, this paper proposes a novel secure SemCom framework for image transmission over wiretap channels, leveraging differential privacy (DP) to provide approximate privacy guarantees. Specifically, our approach first extracts disentangled semantic representations from source images using generative adversarial network (GAN) inversion method, and then selectively perturbs private semantic representations with approximate DP noise. Distinct from conventional DP-based protection methods, we introduce DP noise with learnable pattern, instead of traditional white Gaussian or Laplace noise, achieved through adversarial training of neural networks (NNs). This design mitigates the inherent non-invertibility of DP while effectively protecting private information. Moreover, it enables explicitly controllable security levels by adjusting the privacy budget according to specific security requirements, which is not achieved in most existing secure SemCom approaches. Experimental results demonstrate that, compared with the previous DP-based method and direct transmission, the proposed method significantly degrades the reconstruction quality for the eavesdropper, while introducing only slight degradation in task performance. Under comparable security levels, our approach achieves an LPIPS advantage of 0.06-0.29 and an FPPSR advantage of 0.10-0.86 for the legitimate user compared with the previous DP-based method.",2510.23274v1,http://arxiv.org/abs/2510.23274v1
Analysis of Hematocrit-Plasma Separation in a Trifurcated Microchannel by a Diffusive Flux Model,"Rishi Kumar, Indranil Saha Dalal, K. Muralidhar",2025-10-27,"Platelet-enriched plasma and red blood cells (RBC) are needed in the treatment of blood-related diseases, including anaemia and blood cancer. These essential components must be separated from blood in well-designed experimental setups. If active techniques are used, the blood components are likely to be damaged or contaminated while handling. Passive techniques for component separation are preferred, and their design for effectiveness before manufacturing is the subject of this article. Specifically, the performance of a design consisting of a trifurcated microchannel is examined in the framework of 3D numerical simulation, following similar design ideas in recent experimental studies. The influence of geometrical parameters of the channel, such as width and separation arm angle, inlet extension, flow constriction, and flow parameters, including flow rates, hematocrit concentration, and temperature, is studied. The present study utilizes the diffusive flux model (DFM) to model the shear-driven migration of red blood cells (RBC) in a microchannel along with an appropriate rheology model. The physical mechanism driving separation is the formation of the cell-free layer near the walls, using which the separation efficiency and device effectiveness are quantified. It is found that a microchannel with a smaller width and an extended inlet, along with diluted blood samples of lower hematocrit, is effective for greater separation, while the device performance is less sensitive to the flow rates, flow constriction, and the separator angle.",2510.23270v1,http://arxiv.org/abs/2510.23270v1
Fine details in solar flare ribbons: Statistical insights from observations with the Swedish 1-m Solar Telescope,"Jonas Thoen Faber, Reetika Joshi, Luc Rouppe van der Voort, Sven Wedemeyer, Eilif Sommer Øyre, Ignasi J. Soler Poquet, Aline Rangøy Brunvoll",2025-10-27,"Flare ribbons serve as chromospheric footprints of energy deposition resulting from particle acceleration during magnetic reconnection. Their fine-scale structure provides a valuable tool for probing the dynamics of the flare reconnection process. Our goal is to investigate the fine-scale structure of flare ribbons through multiple observations of flares, utilising data obtained from the Atmospheric Imaging Assembly (AIA) and the Swedish 1-m Solar Telescope (SST). The aligned AIA and SST datasets for the three solar flares were used to examine their overall morphology. The SST datasets were specifically used to identify fine-scale structures within the flare ribbons. For spectroscopic analysis of these fine structures, we applied machine-learning methods (k-means clustering) and Gaussian fitting. Using k-means, we identified elongated features in the flare ribbons, termed as ""riblets"", which are short-lived and jet-like small-scale structures that extend as plasma columns from the flare ribbons. Riblets are more prominent near the solar limb and represent the ribbon front. Riblet widths are consistent across observations, ranging from 110-310 km (0"".15-0"".41), while vertical lengths span 620-1220 km (0"".83-1"".66), with a potential maximum of 2000 km (2"".67), after accounting for projection effects. Detailed H-beta spectral analysis reveals that riblets exhibit a single, redshifted emission component, with velocities of 16-21 km s^1, independent of viewing angle. Our high-resolution observations of the three flare ribbons show that they are not continuous structures, but are composed of vertically extended, fine-scale substructures. These irregular features indicate that the reconnection region is not a smooth, laminar current sheet, but rather a fragmented zone filled with magnetic islands, consistent with the theory of patchy reconnection within the coronal current sheet.",2510.23246v1,http://arxiv.org/abs/2510.23246v1
Progressive Growing of Patch Size: Curriculum Learning for Accelerated and Improved Medical Image Segmentation,"Stefan M. Fischer, Johannes Kiechle, Laura Daza, Lina Felsner, Richard Osuala, Daniel M. Lang, Karim Lekadir, Jan C. Peeken, Julia A. Schnabel",2025-10-27,"In this work, we introduce Progressive Growing of Patch Size, an automatic curriculum learning approach for 3D medical image segmentation. Our approach progressively increases the patch size during model training, resulting in an improved class balance for smaller patch sizes and accelerated convergence of the training process. We evaluate our curriculum approach in two settings: a resource-efficient mode and a performance mode, both regarding Dice score performance and computational costs across 15 diverse and popular 3D medical image segmentation tasks. The resource-efficient mode matches the Dice score performance of the conventional constant patch size sampling baseline with a notable reduction in training time to only 44%. The performance mode improves upon constant patch size segmentation results, achieving a statistically significant relative mean performance gain of 1.28% in Dice Score. Remarkably, across all 15 tasks, our proposed performance mode manages to surpass the constant patch size baseline in Dice Score performance, while simultaneously reducing training time to only 89%. The benefits are particularly pronounced for highly imbalanced tasks such as lesion segmentation tasks. Rigorous experiments demonstrate that our performance mode not only improves mean segmentation performance but also reduces performance variance, yielding more trustworthy model comparison. Furthermore, our findings reveal that the proposed curriculum sampling is not tied to a specific architecture but represents a broadly applicable strategy that consistently boosts performance across diverse segmentation models, including UNet, UNETR, and SwinUNETR. In summary, we show that this simple yet elegant transformation on input data substantially improves both Dice Score performance and training runtime, while being compatible across diverse segmentation backbones.",2510.23241v1,http://arxiv.org/abs/2510.23241v1
VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting,"Hoonhee Cho, Jae-Young Kang, Giwon Lee, Hyemin Yang, Heejun Park, Seokwoo Jung, Kuk-Jin Yoon",2025-10-27,"End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm that unifies perception, prediction, and planning into a holistic, data-driven framework. However, achieving robustness to varying camera viewpoints, a common real-world challenge due to diverse vehicle configurations, remains an open problem. In this work, we propose VR-Drive, a novel E2E-AD framework that addresses viewpoint generalization by jointly learning 3D scene reconstruction as an auxiliary task to enable planning-aware view synthesis. Unlike prior scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference strategy that supports online training-time augmentation from sparse views without additional annotations. To further improve viewpoint consistency, we introduce a viewpoint-mixed memory bank that facilitates temporal interaction across multiple viewpoints and a viewpoint-consistent distillation strategy that transfers knowledge from original to synthesized views. Trained in a fully end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and improves planning under viewpoint shifts. In addition, we release a new benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints, enabling comprehensive analysis. Our results demonstrate that VR-Drive is a scalable and robust solution for the real-world deployment of end-to-end autonomous driving systems.",2510.23205v1,http://arxiv.org/abs/2510.23205v1
DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification,"Lukas Bierling, Davide Pasero, Fleur Dolmans, Helia Ghasemi, Angelo Broere",2025-10-27,"Accurate vertex-level contact prediction between humans and surrounding objects is a prerequisite for high fidelity human object interaction models used in robotics, AR/VR, and behavioral simulation. DECO was the first in the wild estimator for this task but is limited to binary contact maps and struggles with soft surfaces, occlusions, children, and false-positive foot contacts. We address these issues and introduce DecoDINO, a three-branch network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders, class-balanced loss weighting to reduce bias, and patch-level cross-attention for improved local reasoning. Vertex features are finally passed through a lightweight MLP with a softmax to assign semantic contact labels. We also tested a vision-language model (VLM) to integrate text features, but the simpler architecture performed better and was used instead. On the DAMON benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\%$, (ii) halves the geodesic error, and (iii) augments predictions with object-level semantic labels. Ablation studies show that LoRA fine-tuning and the dual encoders are key to these improvements. DecoDINO outperformed the challenge baseline in both tasks of the DAMON Challenge. Our code is available at https://github.com/DavidePasero/deco/tree/main.",2510.23203v1,http://arxiv.org/abs/2510.23203v1
Evaluation of Vision-LLMs in Surveillance Video,"Pascal Benschop, Cristian Meo, Justin Dauwels, Jelte P. Mense",2025-10-27,"The widespread use of cameras in our society has created an overwhelming amount of video data, far exceeding the capacity for human monitoring. This presents a critical challenge for public safety and security, as the timely detection of anomalous or criminal events is crucial for effective response and prevention. The ability for an embodied agent to recognize unexpected events is fundamentally tied to its capacity for spatial reasoning. This paper investigates the spatial reasoning of vision-language models (VLMs) by framing anomalous action recognition as a zero-shot, language-grounded task, addressing the embodied perception challenge of interpreting dynamic 3D scenes from sparse 2D video. Specifically, we investigate whether small, pre-trained vision--LLMs can act as spatially-grounded, zero-shot anomaly detectors by converting video into text descriptions and scoring labels via textual entailment. We evaluate four open models on UCF-Crime and RWF-2000 under prompting and privacy-preserving conditions. Few-shot exemplars can improve accuracy for some models, but may increase false positives, and privacy filters -- especially full-body GAN transforms -- introduce inconsistencies that degrade accuracy. These results chart where current vision--LLMs succeed (simple, spatially salient events) and where they falter (noisy spatial cues, identity obfuscation). Looking forward, we outline concrete paths to strengthen spatial grounding without task-specific training: structure-aware prompts, lightweight spatial memory across clips, scene-graph or 3D-pose priors during description, and privacy methods that preserve action-relevant geometry. This positions zero-shot, language-grounded pipelines as adaptable building blocks for embodied, real-world video understanding. Our implementation for evaluating VLMs is publicly available at: https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition",2510.23190v1,http://arxiv.org/abs/2510.23190v1
Finding 3D Scene Analogies with Multimodal Foundation Models,"Junho Kim, Young Min Kim",2025-10-27,"Connecting current observations with prior experiences helps robots adapt and plan in new, unseen 3D environments. Recently, 3D scene analogies have been proposed to connect two 3D scenes, which are smooth maps that align scene regions with common spatial relationships. These maps enable detailed transfer of trajectories or waypoints, potentially supporting demonstration transfer for imitation learning or task plan transfer across scenes. However, existing methods for the task require additional training and fixed object vocabularies. In this work, we propose to use multimodal foundation models for finding 3D scene analogies in a zero-shot, open-vocabulary setting. Central to our approach is a hybrid neural representation of scenes that consists of a sparse graph based on vision-language model features and a feature field derived from 3D shape foundation models. 3D scene analogies are then found in a coarse-to-fine manner, by first aligning the graph and refining the correspondence with feature fields. Our method can establish accurate correspondences between complex scenes, and we showcase applications in trajectory and waypoint transfer.",2510.23184v1,http://arxiv.org/abs/2510.23184v1
AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes,"Sixian Liu, Chen Xu, Qiang Wang, Donghai Shi, Yiwen Li",2025-10-27,"Multimodal camera-LiDAR fusion technology has found extensive application in 3D object detection, demonstrating encouraging performance. However, existing methods exhibit significant performance degradation in challenging scenarios characterized by sensor degradation or environmental disturbances. We propose a novel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates cross-modal knowledge by identifying reliable patterns for robust detection in complex scenes. Specifically, we first project features from each modality into a unified BEV space and enhance them using a window-based attention mechanism. Subsequently, an adaptive gated fusion module based on cross-modal attention is designed to integrate these features into reliable BEV representations robust to challenging environments. Furthermore, we construct a new dataset named Excavator3D (E3D) focusing on challenging excavator operation scenarios to benchmark performance in complex conditions. Our method not only achieves competitive performance on the standard KITTI dataset with 93.92% accuracy, but also significantly outperforms the baseline by 24.88% on the challenging E3D dataset, demonstrating superior robustness to unreliable modal information in complex industrial scenes.",2510.23151v1,http://arxiv.org/abs/2510.23151v1
"HAPS-ISAC for 6G: Architecture, Design Trade-offs, and a Practical Roadmap","Parisa Kanani, Mohammad Javad Omidi, Mahmoud Modarres-Hashemi, Halim Yanikomeroglu",2025-10-27,"To meet the ambitious goals of next-generation 6G networks, including ultra-high data rates and ubiquitous coverage, we propose a novel high-altitude platform station (HAPS)-based integrated sensing and communication (ISAC) architecture. Operating in the stratosphere, the HAPS functions as both a powerful communication hub and an advanced environmental sensor. Combined with a fleet of cooperative uncrewed aerial vehicles (UAVs), this dual-purpose system forms a scalable and intelligent 3D network. Simulation results indicate that this approach significantly boosts network performance, improves sensing accuracy, and ensures a fairer service distribution across users, outperforming conventional UAV-only baselines. We conclude by outlining the prospective applications and a deployment roadmap for this technology for smart cities and other large-scale environments.",2510.23147v1,http://arxiv.org/abs/2510.23147v1
DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in Traffic Scenarios,"Ziyu Wang, Wenhao Li, Ji Wu",2025-10-27,"3D object detection from multi-view images in traffic scenarios has garnered significant attention in recent years. Many existing approaches rely on object queries that are generated from 3D reference points to localize objects. However, a limitation of these methods is that some reference points are often far from the target object, which can lead to false positive detections. In this paper, we propose a depth-guided query generator for 3D object detection (DQ3D) that leverages depth information and 2D detections to ensure that reference points are sampled from the surface or interior of the object. Furthermore, to address partially occluded objects in current frame, we introduce a hybrid attention mechanism that fuses historical detection results with depth-guided queries, thereby forming hybrid queries. Evaluation on the nuScenes dataset demonstrates that our method outperforms the baseline by 6.3\% in terms of mean Average Precision (mAP) and 4.3\% in the NuScenes Detection Score (NDS).",2510.23144v1,http://arxiv.org/abs/2510.23144v1
EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction,"Taoyu Wu, Yiyi Miao, Jiaxin Guo, Ziyan Chen, Sihang Zhao, Zhuoxiao Li, Zhe Tang, Baoru Huang, Limin Yu",2025-10-27,"In robot-assisted minimally invasive surgery, accurate 3D reconstruction from endoscopic video is vital for downstream tasks and improved outcomes. However, endoscopic scenarios present unique challenges, including photometric inconsistencies, non-rigid tissue motion, and view-dependent highlights. Most 3DGS-based methods that rely solely on appearance constraints for optimizing 3DGS are often insufficient in this context, as these dynamic visual artifacts can mislead the optimization process and lead to inaccurate reconstructions. To address these limitations, we present EndoWave, a unified spatio-temporal Gaussian Splatting framework by incorporating an optical flow-based geometric constraint and a multi-resolution rational wavelet supervision. First, we adopt a unified spatio-temporal Gaussian representation that directly optimizes primitives in a 4D domain. Second, we propose a geometric constraint derived from optical flow to enhance temporal coherence and effectively constrain the 3D structure of the scene. Third, we propose a multi-resolution rational orthogonal wavelet as a constraint, which can effectively separate the details of the endoscope and enhance the rendering performance. Extensive evaluations on two real surgical datasets, EndoNeRF and StereoMIS, demonstrate that our method EndoWave achieves state-of-the-art reconstruction quality and visual accuracy compared to the baseline method.",2510.23087v1,http://arxiv.org/abs/2510.23087v1
Effective numerical integration on complex shaped elements by discrete signed measures,"Laura Rinaldi, Alvise Sommariva, Marco Vianello",2025-10-27,"We discuss a cheap and stable approach to polynomial moment-based compression of multivariate measures by discrete signed measures. The method is based on the availability of an orthonormal basis and a low-cardinality algebraic quadrature formula for an auxiliary measure in a bounding set. Differently from other approaches, no conditioning issue arises since no matrix factorization or inversion is needed. We provide bounds for the sum of the absolute values of the signed measure weights, and we make two examples: efficient quadrature on curved planar elements with spline boundary (in view of the application to high-order FEM/VEM), and compression of QMC integration on 3D elements with complex shape.",2510.23069v1,http://arxiv.org/abs/2510.23069v1
Repeated generalized measurements generated quantum trajectories without stochastic differential equations,"Rutvij Bhavsar, N. D. Hari Dass",2025-10-27,"This paper examines the issue of quantum trajectories generated by repeated POVM and QND measurements acting on a single copy of a system in an unknown state. After an introduction to various aspects of quantum measurements, and an earlier work based on gaussian measurements, which showed the impossibility of determining the unknown state by such repeated measurements, we present the current work based on martingale properties of certain quantities along the trajectory and their convergence from martingale convergence theorems. The main result is that asymptotically all trajectories approach either non degenerate eigenstates or density matrices spanned by the degenerate eigenstates. A unified treatment of both the degenerate and non degenerate cases is given with the help of higher dimensional projectors. The Luders prescription is reproduced for the degenerate case. The distribution of trajectories is shown to be given by the Born rule. Similar conclusions had already been reached by Bauer et al as well as by Amini et al. A detailed comparison of the three approaches is given. All the three avoid using stochastic differential equations. Alter and Yamamoto were the first to investigate repeated measurements on single copies. We make a detailed comparison with their works too. We end with a brief discussion of the robustness of the results against free evolutions as well as some anti-Zeno aspects of the results.",2510.23058v1,http://arxiv.org/abs/2510.23058v1
Mind the Gap - Imaging Buried Interfaces in Twisted Oxide Moirés,"Harikrishnan KP, Xin Wei, Chia-Hao Lee, Dasol Yoon, Yonghun Lee, Kevin J. Crust, Yu-Tsun Shao, Ruijuan Xu, Jong-Hoon Kang, Ce Liang, Jiwoong Park, Harold Y. Hwang, David A. Muller",2025-10-27,"The ability to tune electronic structure in twisted stacks of layered, two-dimensional (2D) materials has motivated the exploration of similar moir\'e physics with stacks of twisted oxide membranes. Due to the intrinsic three-dimensional (3D) nature of bonding in many oxides, achieving atomic-level coupling is significantly more challenging than in 2D van der Waals materials. Although clean interfaces with atomic level proximity have been demonstrated in ceramic bicrystals using high-temperature and high-pressure processing to facilitate atomic diffusion that flattens rough interfaces, such conditions are not readily accessible when bonding oxide membranes. This study shows how topographic mismatch due to surface roughness of the membranes can restrict atomic-scale proximity at the interface to isolated patches even after obvious issues of contaminants and amorphous interlayers are eliminated. In hybrid interfaces between a chemically inert 2D material and an oxide membrane, the reduced ability of the 2D material to conform to the membrane's step-terrace topography also limits atomic-scale contact. In all these material systems, the interface morphology is best characterized using cross-sectional imaging and is necessary to corroborate investigations of interlayer coupling. When imaging the bicrystal in projection, conventional through-focal imaging is found to be relatively insensitive to the buried interface, whereas electron ptychography reliably resolves structural variations on the order of a nanometer. These findings highlight interface roughness as a key challenge for the field of oxide twistronics and emphasizes the need for reliable characterization methods.",2510.23042v1,http://arxiv.org/abs/2510.23042v1
The entropic central limit theorem for stochastic integrable Hamiltonian systems,"Chen Wang, Yong Li",2025-10-27,"In this paper, we investigate the asymptotic stability of finite-dimensional stochastic integrable Hamiltonian systems via information entropy. Specifically, we establish the asymptotic vanishing of Shannon entropy difference (with correction for the lattice interval length) and relative entropy between the partial sum of discretized frequency sequence and its quantized Gaussian approximation (expectation and covariance variance matched). These two convergence are logically consistent with the second law of thermodynamics: the complexity of the system has reached the theoretical limit, and the orbits achieve a global unbiased coverage of the invariant tori with the most thorough chaotic behavior, their average winding rate along the tori stays fixed at the corresponding expected value of the frequency sequence, while deviations from this average follow isotropic Gaussian dynamics, much like Wiener process around a fixed trajectory. This thus provides an information-theoretic quantification of how orbital complexity ensures the persistence of invariant tori beyond mere convergence of statistical distributions (as stated in the classical central limit theorem).",2510.23031v1,http://arxiv.org/abs/2510.23031v1
USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding,"Youssef Megahed, Robin Ducharme, Mark Walker, Steven Hawken, Adrian D. C. Chan",2025-10-27,"Ultrasound imaging is one of the most widely used diagnostic modalities, offering real-time, radiation-free assessment across diverse clinical domains. However, interpretation of ultrasound images remains challenging due to high noise levels, operator dependence, and limited field of view, resulting in substantial inter-observer variability. Current Deep Learning approaches are hindered by the scarcity of large labeled datasets and the domain gap between general and sonographic images, which limits the transferability of models pretrained on non-medical data. To address these challenges, we introduce the Ultrasound Self-Supervised Foundation Model with Masked Autoencoding (USF-MAE), the first large-scale self-supervised MAE framework pretrained exclusively on ultrasound data. The model was pre-trained on 370,000 2D and 3D ultrasound images curated from 46 open-source datasets, collectively termed OpenUS-46, spanning over twenty anatomical regions. This curated dataset has been made publicly available to facilitate further research and reproducibility. Using a Vision Transformer encoder-decoder architecture, USF-MAE reconstructs masked image patches, enabling it to learn rich, modality-specific representations directly from unlabeled data. The pretrained encoder was fine-tuned on three public downstream classification benchmarks: BUS-BRA (breast cancer), MMOTU-2D (ovarian tumors), and GIST514-DB (gastrointestinal stromal tumors). Across all tasks, USF-MAE consistently outperformed conventional CNN and ViT baselines, achieving F1-scores of 81.6%, 79.6%, and 82.4%, respectively. Despite not using labels during pretraining, USF-MAE approached the performance of the supervised foundation model UltraSam on breast cancer classification and surpassed it on the other tasks, demonstrating strong cross-anatomical generalization.",2510.22990v1,http://arxiv.org/abs/2510.22990v1
Equivariant Neural Networks for General Linear Symmetries on Lie Algebras,"Chankyo Kim, Sicheng Zhao, Minghan Zhu, Tzu-Yuan Lin, Maani Ghaffari",2025-10-27,"Encoding symmetries is a powerful inductive bias for improving the generalization of deep neural networks. However, most existing equivariant models are limited to simple symmetries like rotations, failing to address the broader class of general linear transformations, GL(n), that appear in many scientific domains. We introduce Reductive Lie Neurons (ReLNs), a novel neural network architecture exactly equivariant to these general linear symmetries. ReLNs are designed to operate directly on a wide range of structured inputs, including general n-by-n matrices. ReLNs introduce a novel adjoint-invariant bilinear layer to achieve stable equivariance for both Lie-algebraic features and matrix-valued inputs, without requiring redesign for each subgroup. This architecture overcomes the limitations of prior equivariant networks that only apply to compact groups or simple vector data. We validate ReLNs' versatility across a spectrum of tasks: they outperform existing methods on algebraic benchmarks with sl(3) and sp(4) symmetries and achieve competitive results on a Lorentz-equivariant particle physics task. In 3D drone state estimation with geometric uncertainty, ReLNs jointly process velocities and covariances, yielding significant improvements in trajectory accuracy. ReLNs provide a practical and general framework for learning with broad linear group symmetries on Lie algebras and matrix-valued data. Project page: https://reductive-lie-neuron.github.io/",2510.22984v1,http://arxiv.org/abs/2510.22984v1
Exploring Semantic-constrained Adversarial Example with Instruction Uncertainty Reduction,"Jin Hu, Jiakai Wang, Linna Jing, Haolin Li, Haodong Liu, Haotong Qin, Aishan Liu, Ke Xu, Xianglong Liu",2025-10-27,"Recently, semantically constrained adversarial examples (SemanticAE), which are directly generated from natural language instructions, have become a promising avenue for future research due to their flexible attacking forms. To generate SemanticAEs, current methods fall short of satisfactory attacking ability as the key underlying factors of semantic uncertainty in human instructions, such as referring diversity, descriptive incompleteness, and boundary ambiguity, have not been fully investigated. To tackle the issues, this paper develops a multi-dimensional instruction uncertainty reduction (InSUR) framework to generate more satisfactory SemanticAE, i.e., transferable, adaptive, and effective. Specifically, in the dimension of the sampling method, we propose the residual-driven attacking direction stabilization to alleviate the unstable adversarial optimization caused by the diversity of language references. By coarsely predicting the language-guided sampling process, the optimization process will be stabilized by the designed ResAdv-DDIM sampler, therefore releasing the transferable and robust adversarial capability of multi-step diffusion models. In task modeling, we propose the context-encoded attacking scenario constraint to supplement the missing knowledge from incomplete human instructions. Guidance masking and renderer integration are proposed to regulate the constraints of 2D/3D SemanticAE, activating stronger scenario-adapted attacks. Moreover, in the dimension of generator evaluation, we propose the semantic-abstracted attacking evaluation enhancement by clarifying the evaluation boundary, facilitating the development of more effective SemanticAE generators. Extensive experiments demonstrate the superiority of the transfer attack performance of InSUR. Moreover, we realize the reference-free generation of semantically constrained 3D adversarial examples for the first time.",2510.22981v1,http://arxiv.org/abs/2510.22981v1
How Muon's Spectral Design Benefits Generalization: A Study on Imbalanced Data,"Bhavya Vasudeva, Puneesh Deora, Yize Zhao, Vatsal Sharan, Christos Thrampoulidis",2025-10-27,"The growing adoption of spectrum-aware matrix-valued optimizers such as Muon and Shampoo in deep learning motivates a systematic study of their generalization properties and, in particular, when they might outperform competitive algorithms. We approach this question by introducing appropriate simplifying abstractions as follows: First, we use imbalanced data as a testbed. Second, we study the canonical form of such optimizers, which is Spectral Gradient Descent (SpecGD) -- each update step is $UV^T$ where $U\Sigma V^T$ is the truncated SVD of the gradient. Third, within this framework we identify a canonical setting for which we precisely quantify when SpecGD outperforms vanilla Euclidean GD. For a Gaussian mixture data model and both linear and bilinear models, we show that unlike GD, which prioritizes learning dominant principal components of the data first, SpecGD learns all principal components of the data at equal rates. We demonstrate how this translates to a growing gap in balanced accuracy favoring SpecGD early in training and further show that the gap remains consistent even when the GD counterpart uses adaptive step-sizes via normalization. By extending the analysis to deep linear models, we show that depth amplifies these effects. We empirically verify our theoretical findings on a variety of imbalanced datasets. Our experiments compare practical variants of spectral methods, like Muon and Shampoo, against their Euclidean counterparts and Adam. The results validate our findings that these spectral optimizers achieve superior generalization by promoting a more balanced learning of the data's underlying components.",2510.22980v1,http://arxiv.org/abs/2510.22980v1
VoMP: Predicting Volumetric Mechanical Property Fields,"Rishit Dagli, Donglai Xiang, Vismay Modi, Charles Loop, Clement Fuji Tsang, Anka He Chen, Anita Hu, Gavriel State, David I. W. Levin, Maria Shugrina",2025-10-27,"Physical simulation relies on spatially-varying mechanical properties, often laboriously hand-crafted. VoMP is a feed-forward method trained to predict Young's modulus ($E$), Poisson's ratio ($\nu$), and density ($\rho$) throughout the volume of 3D objects, in any representation that can be rendered and voxelized. VoMP aggregates per-voxel multi-view features and passes them to our trained Geometry Transformer to predict per-voxel material latent codes. These latents reside on a manifold of physically plausible materials, which we learn from a real-world dataset, guaranteeing the validity of decoded per-voxel materials. To obtain object-level training data, we propose an annotation pipeline combining knowledge from segmented 3D datasets, material databases, and a vision-language model, along with a new benchmark. Experiments show that VoMP estimates accurate volumetric properties, far outperforming prior art in accuracy and speed.",2510.22975v1,http://arxiv.org/abs/2510.22975v1
Scaling Up Occupancy-centric Driving Scene Generation: Dataset and Method,"Bohan Li, Xin Jin, Hu Zhu, Hongsi Liu, Ruikai Li, Jiazhe Guo, Kaiwen Cai, Chao Ma, Yueming Jin, Hao Zhao, Xiaokang Yang, Wenjun Zeng",2025-10-27,"Driving scene generation is a critical domain for autonomous driving, enabling downstream applications, including perception and planning evaluation. Occupancy-centric methods have recently achieved state-of-the-art results by offering consistent conditioning across frames and modalities; however, their performance heavily depends on annotated occupancy data, which still remains scarce. To overcome this limitation, we curate Nuplan-Occ, the largest semantic occupancy dataset to date, constructed from the widely used Nuplan benchmark. Its scale and diversity facilitate not only large-scale generative modeling but also autonomous driving downstream applications. Based on this dataset, we develop a unified framework that jointly synthesizes high-quality semantic occupancy, multi-view videos, and LiDAR point clouds. Our approach incorporates a spatio-temporal disentangled architecture to support high-fidelity spatial expansion and temporal forecasting of 4D dynamic occupancy. To bridge modal gaps, we further propose two novel techniques: a Gaussian splatting-based sparse point map rendering strategy that enhances multi-view video generation, and a sensor-aware embedding strategy that explicitly models LiDAR sensor properties for realistic multi-LiDAR simulation. Extensive experiments demonstrate that our method achieves superior generation fidelity and scalability compared to existing approaches, and validates its practical value in downstream tasks. Repo: https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation/tree/v2",2510.22973v1,http://arxiv.org/abs/2510.22973v1
End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control,"Benedictus C. G. Cinun, Tua A. Tamba, Immanuel R. Santjoko, Xiaofeng Wang, Michael A. Gunarso, Bin Hu",2025-10-27,"This paper presents the complete design, control, and experimental validation of a low-cost Stewart platform prototype developed as an affordable yet capable robotic testbed for research and education. The platform combines off the shelf components with 3D printed and custom fabricated parts to deliver full six degrees of freedom motions using six linear actuators connecting a moving platform to a fixed base. The system software integrates dynamic modeling, data acquisition, and real time control within a unified framework. A robust trajectory tracking controller based on feedback linearization, augmented with an LQR scheme, compensates for the platform's nonlinear dynamics to achieve precise motion control. In parallel, an Extended Kalman Filter fuses IMU and actuator encoder feedback to provide accurate and reliable state estimation under sensor noise and external disturbances. Unlike prior efforts that emphasize only isolated aspects such as modeling or control, this work delivers a complete hardware-software platform validated through both simulation and experiments on static and dynamic trajectories. Results demonstrate effective trajectory tracking and real-time state estimation, highlighting the platform's potential as a cost effective and versatile tool for advanced research and educational applications.",2510.22949v1,http://arxiv.org/abs/2510.22949v1
Positional Preservation Embedding for Multimodal Large Language Models,"Mouxiao Huang, Borui Jiang, Dehua Zheng, Hailin Hu, Kai Han, Xinghao Chen",2025-10-27,"Multimodal large language models (MLLMs) have achieved strong performance on vision-language tasks, yet often suffer from inefficiencies due to redundant visual tokens. Existing token merging methods reduce sequence length but frequently disrupt spatial layouts and temporal continuity by disregarding positional relationships. In this work, we propose a novel encoding operator dubbed as \textbf{P}ositional \textbf{P}reservation \textbf{E}mbedding (\textbf{PPE}), which has the main hallmark of preservation of spatiotemporal structure during visual token compression. PPE explicitly introduces the disentangled encoding of 3D positions in the token dimension, enabling each compressed token to encapsulate different positions from multiple original tokens. Furthermore, we show that PPE can effectively support cascade clustering -- a progressive token compression strategy that leads to better performance retention. PPE is a parameter-free and generic operator that can be seamlessly integrated into existing token merging methods without any adjustments. Applied to state-of-the-art token merging framework, PPE achieves consistent improvements of $2\%\sim5\%$ across multiple vision-language benchmarks, including MMBench (general vision understanding), TextVQA (layout understanding) and VideoMME (temporal understanding). These results demonstrate that preserving positional cues is critical for efficient and effective MLLM reasoning.",2510.22936v1,http://arxiv.org/abs/2510.22936v1
A parametric study of the broadband shock-associated noise in supersonic jets via semi-empirical modeling,"Binhong Li, Benshuai Lyu",2025-10-27,"A semi-empirical model is developed in this paper to predict the broadband shock-associated noise (BBSAN) generated by shock-instability interaction (SII) in imperfectly expanded supersonic jets. The model makes use of a semi-empirically modified Pack's model that accounts for the decay in both shock amplitude and shock spacing and a Gaussian wave-packet model for the instability waves. The near-field pressure perturbation due to the SII is treated as a boundary value for the Helmholtz equation, which is subsequently solved to predict the far-field acoustic spectra and directivity patterns. A comprehensive parametric study is conducted to reveal the effects of the key parameters on the acoustic spectral and directivity features. It is found that decreasing the instability-wave decay rate narrows the spectral bandwidth and the major lobes in directivity patterns, while variations in shock spacing shift the spectral peak frequency and the major radiation angle. Mechanisms of such changes are discussed based on the model. Further validation against multiple experimental datasets demonstrates that incorporating more realistic parameters in the model-particularly those accounting for the shock spacing and amplitude decays-considerably improves its prediction accuracy and physical consistency. The improved model successfully reproduces several key spectral features observed in experiments; these include, for example, the peak frequency and the tendency of bandwidth contradiction as the observer angle increases. Moreover, the predicted directivity patterns closely match the experiments outside the shallow-angle region dominated by jet mixing noise. In particular, it captures the major radiation lobes and their frequency-dependent amplitude and shape variations.",2510.22935v1,http://arxiv.org/abs/2510.22935v1
Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression,Pranav Saxena,2025-10-27,"Modeling open-vocabulary language fields in 3D is essential for intuitive human-AI interaction and querying within physical environments. State-of-the-art approaches, such as LangSplat, leverage 3D Gaussian Splatting to efficiently construct these language fields, encoding features distilled from high-dimensional models like CLIP. However, this efficiency is currently offset by the requirement to train a scene-specific language autoencoder for feature compression, introducing a costly, per-scene optimization bottleneck that hinders deployment scalability. In this work, we introduce Gen-LangSplat, that eliminates this requirement by replacing the scene-wise autoencoder with a generalized autoencoder, pre-trained extensively on the large-scale ScanNet dataset. This architectural shift enables the use of a fixed, compact latent space for language features across any new scene without any scene-specific training. By removing this dependency, our entire language field construction process achieves a efficiency boost while delivering querying performance comparable to, or exceeding, the original LangSplat method. To validate our design choice, we perform a thorough ablation study empirically determining the optimal latent embedding dimension and quantifying representational fidelity using Mean Squared Error and cosine similarity between the original and reprojected 512-dimensional CLIP embeddings. Our results demonstrate that generalized embeddings can efficiently and accurately support open-vocabulary querying in novel 3D scenes, paving the way for scalable, real-time interactive 3D AI applications.",2510.22930v1,http://arxiv.org/abs/2510.22930v1
Control of Valence Electron Motion in Xe Cation Using Stimulated Raman Adiabatic Passage Technique,"Miguel Alarcón, Karl Hauser, Nikolay V. Golubev",2025-10-26,"This work theoretically investigates possibilities of using the Stimulated Raman Adiabatic Passage (STIRAP) and its variants to control a coherent superposition of quantum states. We present a generalization of the so-called fractional STIRAP (f-STIRAP), demonstrating precise control over the mixing ratio of quantum states in the wave packet. In contrast to conventional f-STIRAP, designed to drive a system from an eigenstate into a coherent superposition, our scheme enables arbitrary control over the composition of an already existing superposition state. We demonstrate that an approximate version of this technique -- where analytically designed laser pulses with composite envelopes are replaced by simple Gaussian pulses -- achieves comparable performance in controlling the dynamics of the wave packet. A limiting case of this scheme, utilizing two pulses with identical Gaussians envelopes and tuned delay and relative phase, is also explored, revealing experimentally accessible pathways for manipulating quantum coherence. We apply our developed techniques to control the ultrafast charge migration in the spin-orbit split ground electronic states of xenon cation via intermediate valence- and core-excited states. Finally, we propose concrete experimental realizations of the developed control schemes in combination with attosecond transient absorption spectroscopy as a method to probe the system.",2510.22875v1,http://arxiv.org/abs/2510.22875v1
Region-Adaptive Learned Hierarchical Encoding for 3D Gaussian Splatting Data,"Shashank N. Sridhara, Birendra Kathariya, Fangjun Pu, Peng Yin, Eduardo Pavez, Antonio Ortega",2025-10-26,"We introduce Region-Adaptive Learned Hierarchical Encoding (RALHE) for 3D Gaussian Splatting (3DGS) data. While 3DGS has recently become popular for novel view synthesis, the size of trained models limits its deployment in bandwidth-constrained applications such as volumetric media streaming. To address this, we propose a learned hierarchical latent representation that builds upon the principles of ""overfitted"" learned image compression (e.g., Cool-Chic and C3) to efficiently encode 3DGS attributes. Unlike images, 3DGS data have irregular spatial distributions of Gaussians (geometry) and consist of multiple attributes (signals) defined on the irregular geometry. Our codec is designed to account for these differences between images and 3DGS. Specifically, we leverage the octree structure of the voxelized 3DGS geometry to obtain a hierarchical multi-resolution representation. Our approach overfits latents to each Gaussian attribute under a global rate constraint. These latents are decoded independently through a lightweight decoder network. To estimate the bitrate during training, we employ an autoregressive probability model that leverages octree-derived contexts from the 3D point structure. The multi-resolution latents, decoder, and autoregressive entropy coding networks are jointly optimized for each Gaussian attribute. Experiments demonstrate that the proposed RALHE compression framework achieves a rendering PSNR gain of up to 2dB at low bitrates (less than 1 MB) compared to the baseline 3DGS compression methods.",2510.22812v1,http://arxiv.org/abs/2510.22812v1
Propagation of Velocity Moments for the Magnetized Vlasov-Poisson System with Space-Time Dependent Magnetic Fields,"Immanuel Ben Porat, Antoine Gagnebin, Mikaela Iacobelli, Jonathan Junné",2025-10-26,"We prove that polynomial velocity moments of solutions to the 2D magnetized Vlasov-Poisson system and the 3D magnetized screened Vlasov-Poisson equation remain finite for all times, provided they are finite initially, even when the external magnetic field $B=B(t,x)$ is space-time dependent. We deduce propagation of regularity, thereby implying the existence of global classical solutions. Moreover, we prove optimal stability estimates in the kinetic-Wasserstein distance on par with the unmagnetised case.",2510.22753v1,http://arxiv.org/abs/2510.22753v1
SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping,"Wentao Guo, Wenzeng Zhang",2025-10-26,"This paper presents environment-adaptive pinch-lifting built on a slot-constrained adaptive linkage (SCAL) and instantiated in two complementary fingers: SCAL-R, a rotational-drive design with an active fingertip that folds inward after contact to form an envelope, and SCAL-L, a linear-drive design that passively opens on contact to span wide or weak-feature objects. Both fingers convert surface following into an upward lifting branch while maintaining fingertip orientation, enabling thin or low-profile targets to be raised from supports with minimal sensing and control. Two-finger grippers are fabricated via PLA-based 3D printing. Experiments evaluate (i) contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp negotiation followed by lift, and (iii) handling of bulky objects via active enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across dozens of trials on small parts, boxes, jars, and tape rolls, both designs achieve consistent grasps with limited tuning. A quasi-static analysis provides closed-form fingertip-force models for linear parallel pinching and two-point enveloping, offering geometry-aware guidance for design and operation. Overall, the results indicate complementary operating regimes and a practical path to robust, environment-adaptive grasping with simple actuation.",2510.22738v1,http://arxiv.org/abs/2510.22738v1
Centrum: Model-based Database Auto-tuning with Minimal Distributional Assumptions,"Yuanhao Lai, Pengfei Zheng, Chenpeng Ji, Yan Li, Songhan Zhang, Rutao Zhang, Zhengang Wang, Yunfei Du",2025-10-26,"Gaussian-Process-based Bayesian optimization (GP-BO), is a prevailing model-based framework for DBMS auto-tuning. However, recent work shows GP-BO-based DBMS auto-tuners significantly outperformed auto-tuners based on SMAC, which features random forest surrogate models; such results motivate us to rethink and investigate the limitations of GP-BO in auto-tuner design. We find the fundamental assumptions of GP-BO are widely violated when modeling and optimizing DBMS performance, while tree-ensemble-BOs (e.g., SMAC) can avoid the assumption pitfalls and deliver improved tuning efficiency and effectiveness. Moreover, we argue that existing tree-ensemble-BOs restrict further advancement in DBMS auto-tuning. First, existing tree-ensemble-BOs can only achieve distribution-free point estimates, but still impose unrealistic distributional assumptions on uncertainty estimates, compromising surrogate modeling and distort the acquisition function. Second, recent advances in gradient boosting, which can further enhance surrogate modeling against vanilla GP and random forest counterparts, have rarely been applied in optimizing DBMS auto-tuners. To address these issues, we propose a novel model-based DBMS auto-tuner, Centrum. Centrum improves distribution-free point and interval estimation in surrogate modeling with a two-phase learning procedure of stochastic gradient boosting ensembles. Moreover, Centrum adopts a generalized SGBE-estimated locally-adaptive conformal prediction to facilitate a distribution-free uncertainty estimation and acquisition function. To our knowledge, Centrum is the first auto-tuner to realize distribution-freeness, enhancing BO's practicality in DBMS auto-tuning, and the first to seamlessly fuse gradient boosting ensembles and conformal inference in BO. Extensive physical and simulation experiments on two DBMSs and three workloads show Centrum outperforms 21 SOTA methods.",2510.22734v1,http://arxiv.org/abs/2510.22734v1
Reducing Ion Heating in Quantum Computing: A Novel 3D-Printed Micro Ion Trap with Skeleton Structure,"Chon-Teng Belmiro Chu, Hao-Chung Chen, Ting Hsu, Hsiang-Yu Lo, Ming-Shien Chang, Guin-Dar Lin",2025-10-26,"Electric-field-induced ion heating is a major obstacle in scalable trapped-ion quantum computing. We present a theoretical study of a novel 3D-printed ion trap with a skeleton electrode structure, designed to reduce heating by minimizing surface area near the ion. Compared to a conventional blade trap with identical confinement parameters, the skeleton trap achieves over 50% reduction in total heating rate. Patch-by-patch analysis reveals that heating is dominated by surfaces within 500 {\mu}m of the ion. For axial motion, the peak heating occurs approximately 110 {\mu}m away due to electric field directionality. We demonstrate that minor geometric optimization, in which the electrode gaps are realigned with these hotspots, can further suppress heating despite the associated increase in surface area. A linear relationship between ion-to-electrode distance and peak heating location is also established. These results highlight the potential of 3D-printed electrode designs for achieving both strong confinement and reduced noise in future quantum systems.",2510.22725v1,http://arxiv.org/abs/2510.22725v1
Testing Copula Hypothesis with Copula Entropy,Jian Ma,2025-10-26,Testing copula hypothesis is of fundamental importance in the applications of copula theory. In this paper we proposed a copula hypothesis testing with copula entropy. Since copula entropy is a unified theory in probability and therefore testing copula hypothesis based on it can be applied to any types of copula function. The test statistic is defined as the difference of copula entropy of copula hypothesis and true copula entropy. We propose the estimation method of the proposed statistic and two special cases for Gaussian copula hypothesis and Gumbel copula hypothesis. We test the effectiveness of the proposed method with simulation experiments.,2510.22722v1,http://arxiv.org/abs/2510.22722v1
Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication,"Yujie Wan, Chenxuan Liu, Shuai Wang, Tong Zhang, James Jianqiao Yu, Kejiang Ye, Dusit Niyato, Chengzhong Xu",2025-10-26,"Gaussian splatting (GS) struggles with degraded rendering quality on low-cost devices. To address this issue, we present edge collaborative GS (ECO-GS), where each user can switch between a local small GS model to guarantee timeliness and a remote large GS model to guarantee fidelity. However, deciding how to engage the large GS model is nontrivial, due to the interdependency between rendering requirements and resource conditions. To this end, we propose integrated rendering and communication (IRAC), which jointly optimizes collaboration status (i.e., deciding whether to engage large GS) and edge power allocation (i.e., enabling remote rendering) under communication constraints across different users by minimizing a newly-derived GS switching function. Despite the nonconvexity of the problem, we propose an efficient penalty majorization minimization (PMM) algorithm to obtain the critical point solution. Furthermore, we develop an imitation learning optimization (ILO) algorithm, which reduces the computational time by over 100x compared to PMM. Experiments demonstrate the superiority of PMM and the real-time execution capability of ILO.",2510.22718v1,http://arxiv.org/abs/2510.22718v1
Identification of Causal Direction under an Arbitrary Number of Latent Confounders,"Wei Chen, Linjun Peng, Zhiyi Huang, Haoyue Dai, Zhifeng Hao, Ruichu Cai, Kun Zhang",2025-10-26,"Recovering causal structure in the presence of latent variables is an important but challenging task. While many methods have been proposed to handle it, most of them require strict and/or untestable assumptions on the causal structure. In real-world scenarios, observed variables may be affected by multiple latent variables simultaneously, which, generally speaking, cannot be handled by these methods. In this paper, we consider the linear, non-Gaussian case, and make use of the joint higher-order cumulant matrix of the observed variables constructed in a specific way. We show that, surprisingly, causal asymmetry between two observed variables can be directly seen from the rank deficiency properties of such higher-order cumulant matrices, even in the presence of an arbitrary number of latent confounders. Identifiability results are established, and the corresponding identification methods do not even involve iterative procedures. Experimental results demonstrate the effectiveness and asymptotic correctness of our proposed method.",2510.22711v1,http://arxiv.org/abs/2510.22711v1
IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction,"Hao Li, Zhengyu Zou, Fangfu Liu, Xuanyang Zhang, Fangzhou Hong, Yukang Cao, Yushi Lan, Manyuan Zhang, Gang Yu, Dingwen Zhang, Ziwei Liu",2025-10-26,"Humans naturally perceive the geometric structure and semantic content of a 3D world as intertwined dimensions, enabling coherent and accurate understanding of complex scenes. However, most prior approaches prioritize training large geometry models for low-level 3D reconstruction and treat high-level spatial understanding in isolation, overlooking the crucial interplay between these two fundamental aspects of 3D-scene analysis, thereby limiting generalization and leading to poor performance in downstream 3D understanding tasks. Recent attempts have mitigated this issue by simply aligning 3D models with specific language models, thus restricting perception to the aligned model's capacity and limiting adaptability to downstream tasks. In this paper, we propose InstanceGrounded Geometry Transformer (IGGT), an end-to-end large unified transformer to unify the knowledge for both spatial reconstruction and instance-level contextual understanding. Specifically, we design a 3D-Consistent Contrastive Learning strategy that guides IGGT to encode a unified representation with geometric structures and instance-grounded clustering through only 2D visual inputs. This representation supports consistent lifting of 2D visual inputs into a coherent 3D scene with explicitly distinct object instances. To facilitate this task, we further construct InsScene-15K, a large-scale dataset with high-quality RGB images, poses, depth maps, and 3D-consistent instance-level mask annotations with a novel data curation pipeline.",2510.22706v1,http://arxiv.org/abs/2510.22706v1
Gaussian fluctuations in mean field stable matchings,"Daniel Ahlberg, Maria Deijfen, Tiffany Y. Y. Lo",2025-10-26,"Two sets of objects of size $n$ are to be matched to each other based on i.i.d. costs associated to every pair of objects. Objects prefer to be matched as cheaply as possible, and a matching is said to be stable if there is no pair of objects that would prefer to match to each other rather than to their current partners. Properties of such matchings are analysed for cost distributions with a density $\rho$ satisfying $\rho(x)/(dx^{d-1})\to 1$ as $x\to 0^+$, where the number $d$ is known as the pseudo-dimension. For $d>0$, the typical matching cost is shown to be of order $n^{-1/d}$, with an explicit distributional limit. For $d>1$ the total matching cost is shown to be of order $n^{1-1/d}$, and to obey a law of large numbers. For $d>2$ the fluctuations of the total matching cost are shown to be of order $n^{1/2-1/d}$, and to obey a central limit theorem.",2510.22701v1,http://arxiv.org/abs/2510.22701v1
RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets,"Matteo El-Hariry, Andrej Orsula, Matthieu Geist, Miguel Olivares-Mendez",2025-10-26,"The growing need for autonomous on-orbit services such as inspection, maintenance, and situational awareness calls for intelligent spacecraft capable of complex maneuvers around large orbital targets. Traditional control systems often fall short in adaptability, especially under model uncertainties, multi-spacecraft configurations, or dynamically evolving mission contexts. This paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB), we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as model-free baselines. Our investigation focuses on 3D proximity maneuvering tasks around targets such as the Lunar Gateway and other space assets. We evaluate task performance under two complementary regimes: generalized agents trained on randomized velocity vectors, and specialized agents trained to follow fixed trajectories emulating known inspection orbits. Furthermore, we assess the robustness and generalization of policies across multiple spacecraft morphologies and mission domains. Results demonstrate that model-based RL offers promising capabilities in trajectory fidelity, and sample efficiency, paving the way for scalable, retrainable control solutions for future space operations",2510.22699v1,http://arxiv.org/abs/2510.22699v1
SRP-PHAT-NET: A Reliability-Driven DNN for Reverberant Speaker Localization,"Bar Shaybet, Vladimir Tourbabin, Boaz Rafaely",2025-10-26,"Accurate Direction-of-Arrival (DOA) estimation in reverberant environments remains a fundamental challenge for spatial audio applications. While deep learning methods have shown strong performance in such conditions, they typically lack a mechanism to assess the reliability of their predictions - an essential feature for real-world deployment. In this work, we present the SRP-PHAT-NET, a deep neural network framework that leverages SRP-PHAT directional maps as spatial features and introduces a built-in reliability estimation. To enable meaningful reliability scoring, the model is trained using Gaussian-weighted labels centered around the true direction. We systematically analyze the influence of label smoothing on accuracy and reliability, demonstrating that the choice of Gaussian kernel width can be tuned to application-specific requirements. Experimental results show that selectively using high-confidence predictions yields significantly improved localization accuracy, highlighting the practical benefits of integrating reliability into deep learning-based DOA estimation.",2510.22682v1,http://arxiv.org/abs/2510.22682v1
Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views,"Anna Deichler, Jonas Beskow",2025-10-26,"We introduce Look and Tell, a multimodal dataset for studying referential communication across egocentric and exocentric perspectives. Using Meta Project Aria smart glasses and stationary cameras, we recorded synchronized gaze, speech, and video as 25 participants instructed a partner to identify ingredients in a kitchen. Combined with 3D scene reconstructions, this setup provides a benchmark for evaluating how different spatial representations (2D vs. 3D; ego vs. exo) affect multimodal grounding. The dataset contains 3.67 hours of recordings, including 2,707 richly annotated referential expressions, and is designed to advance the development of embodied agents that can understand and engage in situated dialogue.",2510.22672v1,http://arxiv.org/abs/2510.22672v1
LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering,"Wenkai Zhu, Xu Li, Qimin Xu, Benwu Wang, Kun Wei, Yiming Peng, Zihang Wang",2025-10-26,"3D Gaussian Splatting SLAM has emerged as a widely used technique for high-fidelity mapping in spatial intelligence. However, existing methods often rely on a single representation scheme, which limits their performance in large-scale dynamic outdoor scenes and leads to cumulative pose errors and scale ambiguity. To address these challenges, we propose \textbf{LVD-GS}, a novel LiDAR-Visual 3D Gaussian Splatting SLAM system. Motivated by the human chain-of-thought process for information seeking, we introduce a hierarchical collaborative representation module that facilitates mutual reinforcement for mapping optimization, effectively mitigating scale drift and enhancing reconstruction robustness. Furthermore, to effectively eliminate the influence of dynamic objects, we propose a joint dynamic modeling module that generates fine-grained dynamic masks by fusing open-world segmentation with implicit residual constraints, guided by uncertainty estimates from DINO-Depth features. Extensive evaluations on KITTI, nuScenes, and self-collected datasets demonstrate that our approach achieves state-of-the-art performance compared to existing methods.",2510.22669v1,http://arxiv.org/abs/2510.22669v1
"The Gravitational Aspect of Information: The Physical Reality of Asymmetric ""Distance""","Tomoi Koide, Armin van de Venn",2025-10-26,"We demonstrate that when a Brownian bridge is physically constrained to be canonical, its time evolution becomes identical to an m-geodesic on the statistical manifold of Gaussian distributions. This finding provides strong evidence that, akin to general relativity where free particles follow geodesics, purely random processes also follow ``straight lines"" defined by the geometry of information. This geometric principle is a direct consequence of the dually flat structure inherent to information geometry, originating from the asymmetry of informational ``distance"" (divergence) leading to the violation of metric compatibility. Our results suggest a geometric foundation for randomness and open the door to an equivalence principle for information.",2510.22664v1,http://arxiv.org/abs/2510.22664v1
Data-driven dimensionally decomposed generalized polynomial chaos expansion for forward uncertainty quantification,"Hojun Choi, Eunho Heo, Dongjin Lee",2025-10-26,"Dimensionally decomposed generalized polynomial chaos expansion (DD-GPCE) efficiently performs forward uncertainty quantification (UQ) in complex engineering systems with high-dimensional random inputs of arbitrary distributions. However, constructing the measure-consistent orthonormal polynomial bases in DD-GPCE requires prior knowledge of input distributions, which is often unavailable in practice. This work introduces a data-driven DD-GPCE method that eliminates the need for such prior knowledge, extending its applicability to UQ with high-dimensional inputs. Input distributions are inferred directly from sample data using smoothed-bootstrap kernel density estimation (KDE), while the DD-GPCE framework enables KDE to handle high-dimensional inputs through low-dimensional marginal estimation. We then use the estimated input distributions to perform a whitening transformation via Monte Carlo Simulation, which enables generation of measure-consistent orthonormal basis functions. We demonstrate the accuracy of the proposed method in both mathematical examples and stochastic dynamic analysis for a practical three-dimensional mobility design involving twenty random inputs. The results indicate that the proposed method produces more accurate estimates of the output mean and variance compared to the conventional data-driven approach that assumes Gaussian input distributions.",2510.22642v1,http://arxiv.org/abs/2510.22642v1
RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience,"Huilin Yin, Zhaolin Yang, Linchuan Zhang, Gerhard Rigoll, Johannes Betz",2025-10-26,"The reliability of Simultaneous Localization and Mapping (SLAM) is severely constrained in environments where visual inputs suffer from noise and low illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM frameworks achieve high-fidelity mapping under clean conditions, they remain vulnerable to compounded degradations that degrade mapping and tracking performance. A key observation underlying our work is that the original 3DGS rendering pipeline inherently behaves as an implicit low-pass filter, attenuating high-frequency noise but also risking over-smoothing. Building on this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for noise and low-light resilience. The framework integrates three innovations: a Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples rendered appearance, depth, and edge cues; an adaptive tracking objective with residual balancing regularization; and a Contrastive Language-Image Pretraining (CLIP)-based enhancement module, selectively activated under compounded degradations to restore semantic and structural fidelity. Comprehensive experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM consistently improves trajectory accuracy and reconstruction quality compared with other 3DGS-SLAM systems, especially under adverse imaging conditions.",2510.22600v1,http://arxiv.org/abs/2510.22600v1
PSScreen V2: Partially Supervised Multiple Retinal Disease Screening,"Boyi Zheng, Yalin Zheng, Hrvoje Bogunović, Qing Liu",2025-10-26,"In this work, we propose PSScreen V2, a partially supervised self-training framework for multiple retinal disease screening. Unlike previous methods that rely on fully labelled or single-domain datasets, PSScreen V2 is designed to learn from multiple partially labelled datasets with different distributions, addressing both label absence and domain shift challenges. To this end, PSScreen V2 adopts a three-branch architecture with one teacher and two student networks. The teacher branch generates pseudo labels from weakly augmented images to address missing labels, while the two student branches introduce novel feature augmentation strategies: Low-Frequency Dropout (LF-Dropout), which enhances domain robustness by randomly discarding domain-related low-frequency components, and Low-Frequency Uncertainty (LF-Uncert), which estimates uncertain domain variability via adversarially learned Gaussian perturbations of low-frequency statistics. Extensive experiments on multiple in-domain and out-of-domain fundus datasets demonstrate that PSScreen V2 achieves state-of-the-art performance and superior domain generalization ability. Furthermore, compatibility tests with diverse backbones, including the vision foundation model DINOv2, as well as evaluations on chest X-ray datasets, highlight the universality and adaptability of the proposed framework. The codes are available at https://github.com/boyiZheng99/PSScreen_V2.",2510.22589v1,http://arxiv.org/abs/2510.22589v1
From Pixels to Views: Learning Angular-Aware and Physics-Consistent Representations for Light Field Microscopy,"Feng He, Guodong Tan, Qiankun Li, Jun Yu, Quan Wen",2025-10-26,"Light field microscopy (LFM) has become an emerging tool in neuroscience for large-scale neural imaging in vivo, notable for its single-exposure volumetric imaging, broad field of view, and high temporal resolution. However, learning-based 3D reconstruction in XLFM remains underdeveloped due to two core challenges: the absence of standardized datasets and the lack of methods that can efficiently model its angular-spatial structure while remaining physically grounded. We address these challenges by introducing three key contributions. First, we construct the XLFM-Zebrafish benchmark, a large-scale dataset and evaluation suite for XLFM reconstruction. Second, we propose Masked View Modeling for Light Fields (MVN-LF), a self-supervised task that learns angular priors by predicting occluded views, improving data efficiency. Third, we formulate the Optical Rendering Consistency Loss (ORC Loss), a differentiable rendering constraint that enforces alignment between predicted volumes and their PSF-based forward projections. On the XLFM-Zebrafish benchmark, our method improves PSNR by 7.7% over state-of-the-art baselines.",2510.22577v1,http://arxiv.org/abs/2510.22577v1
Some aspects of neural network parameter optimization for joint inversion of gravitational and magnetic fields,"Yanfei Wang, Dmitry V. Churbanov, Raul L. Argun, Alexander V. Gorbachev, Alexander S. Leonov, Dmitry V. Lukyanenko",2025-10-26,"We consider the optimization of a neural network previously developed by the authors for the joint inversion of 3D gravitational and magnetic fields in the context of mineral exploration. The distinctive feature of this neural network is that it solves ill-posed (ill-conditioned) inverse problems. The neural network implements a special two-level algorithm. The lower level of the algorithm uses two neural networks with equivalent architectures. The first of them computes the gravitational field sources in a given domain from measurements of this field on a remote surface. The second neural network processes magnetic field measured on the same surface to find magnetic sources in the same domain. The found source distributions are used at the upper level of the algorithm to calculate their structural residual, which determines the degree of difference (closeness) of their geometries. As a result, minimizing this residual, when training a neural network at the upper level, implements a computational algorithm that yields geometrically close source distributions of different fields. The article examines in detail the possibilities of optimizing some elements of the neural networks and the algorithms used (datasets, training process, specific form of loss functions, etc.) Test calculations for model problem demonstrate high quality of joint inversion by our optimized neural networks approach. Calculations were also carried out for the joint processing of real-feald data from gravity and magnetic exploration in Jussara region, Goias State, Brazil. The article also considers the issue of determining in joint field inversion not only the geometric distribution of sources, but also their physical intensities.",2510.22564v1,http://arxiv.org/abs/2510.22564v1
LO-SDA: Latent Optimization for Score-based Atmospheric Data Assimilation,"Jing-An Sun, Hang Fan, Junchao Gong, Ben Fei, Kun Chen, Fenghua Ling, Wenlong Zhang, Wanghan Xu, Li Yan, Pierre Gentine, Lei Bai",2025-10-26,"Data assimilation (DA) plays a pivotal role in numerical weather prediction by systematically integrating sparse observations with model forecasts to estimate optimal atmospheric initial condition for forthcoming forecasts. Traditional Bayesian DA methods adopt a Gaussian background prior as a practical compromise for the curse of dimensionality in atmospheric systems, that simplifies the nonlinear nature of atmospheric dynamics and can result in biased estimates. To address this limitation, we propose a novel generative DA method, LO-SDA. First, a variational autoencoder is trained to learn compact latent representations that disentangle complex atmospheric correlations. Within this latent space, a background-conditioned diffusion model is employed to directly learn the conditional distribution from data, thereby generalizing and removing assumptions in the Gaussian prior in traditional DA methods. Most importantly, we introduce latent optimization during the reverse process of the diffusion model to ensure strict consistency between the generated states and sparse observations. Idealized experiments demonstrate that LO-SDA not only outperforms score-based DA methods based on diffusion posterior sampling but also surpasses traditional DA approaches. To our knowledge, this is the first time that a diffusion-based DA method demonstrates the potential to outperform traditional approaches on high-dimensional global atmospheric systems. These findings suggest that long-standing reliance on Gaussian priors-a foundational assumption in operational atmospheric DA-may no longer be necessary in light of advances in generative modeling.",2510.22562v1,http://arxiv.org/abs/2510.22562v1
Surface decomposition method for sensitivity analysis of first-passage dynamic reliability of linear systems,"Jianhua Xian, Sai Hung Cheung, Cheng Su",2025-10-26,"This work presents a novel surface decomposition method for the sensitivity analysis of first-passage dynamic reliability of linear systems subjected to Gaussian random excitations. The method decomposes the sensitivity of first-passage failure probability into a sum of surface integrals over the constrained component limit-state hypersurfaces. The evaluation of these surface integrals can be accomplished, owing to the availability of closed-form linear expressions of both the component limit-state functions and their sensitivities for linear systems. An importance sampling strategy is introduced to further enhance the efficiency for estimating the sum of these surface integrals. The number of function evaluations required for the reliability sensitivity analysis is typically on the order of 10^2 to 10^3. The approach is particularly advantageous when a large number of design parameters are considered, as the results of function evaluations can be reused across different parameters. Two numerical examples are investigated to demonstrate the effectiveness of the proposed method.",2510.22558v1,http://arxiv.org/abs/2510.22558v1
CANDI: Hybrid Discrete-Continuous Diffusion Models,"Patrick Pynadath, Jiaxin Shi, Ruqi Zhang",2025-10-26,"While continuous diffusion has shown remarkable success in continuous domains such as image generation, its direct application to discrete data has underperformed compared to purely discrete formulations. This gap is counterintuitive, given that continuous diffusion learns score functions that enable joint evolution across multiple positions. To understand this gap, we introduce token identifiability as an analytical framework for understanding how Gaussian noise corrupts discrete data through two mechanisms: discrete identity corruption and continuous rank degradation. We reveal that these mechanisms scale differently with vocabulary size, creating a temporal dissonance: at noise levels where discrete corruption preserves enough structure for conditional learning, continuous denoising is trivial; at noise levels where continuous denoising is meaningful, discrete corruption destroys nearly all conditional structure. To solve this, we propose CANDI (Continuous ANd DIscrete diffusion), a hybrid framework that decouples discrete and continuous corruption, enabling simultaneous learning of both conditional structure and continuous geometry. We empirically validate the temporal dissonance phenomenon and demonstrate that CANDI successfully avoids it. This unlocks the benefits of continuous diffusion for discrete spaces: on controlled generation, CANDI enables classifier-based guidance with off-the-shelf classifiers through simple gradient addition; on text generation, CANDI outperforms masked diffusion at low NFE, demonstrating the value of learning continuous gradients for discrete spaces.",2510.22510v1,http://arxiv.org/abs/2510.22510v1
GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis,"Rui Jin, Chen Chen, Yin Liu, Hongfu Sun, Min Zeng, Min Li, Yang Gao",2025-10-26,"Accurate diagnosis of Parkinson's disease (PD) from MRI remains challenging due to symptom variability and pathological heterogeneity. Most existing methods rely on conventional magnitude-based MRI modalities, such as T1-weighted images (T1w), which are less sensitive to PD pathology than Quantitative Susceptibility Mapping (QSM), a phase-based MRI technique that quantifies iron deposition in deep gray matter nuclei. In this study, we propose GateFuseNet, an adaptive 3D multimodal fusion network that integrates QSM and T1w images for PD diagnosis. The core innovation lies in a gated fusion module that learns modality-specific attention weights and channel-wise gating vectors for selective feature modulation. This hierarchical gating mechanism enhances ROI-aware features while suppressing irrelevant signals. Experimental results show that our method outperforms three existing state-of-the-art approaches, achieving 85.00% accuracy and 92.06% AUC. Ablation studies further validate the contributions of ROI guidance, multimodal integration, and fusion positioning. Grad-CAM visualizations confirm the model's focus on clinically relevant pathological regions. The source codes and pretrained models can be found at https://github.com/YangGaoUQ/GateFuseNet",2510.22507v1,http://arxiv.org/abs/2510.22507v1
LAMP: Data-Efficient Linear Affine Weight-Space Models for Parameter-Controlled 3D Shape Generation and Extrapolation,"Ghadi Nehme, Yanxia Zhang, Dule Shu, Matt Klenk, Faez Ahmed",2025-10-26,"Generating high-fidelity 3D geometries that satisfy specific parameter constraints has broad applications in design and engineering. However, current methods typically rely on large training datasets and struggle with controllability and generalization beyond the training distributions. To overcome these limitations, we introduce LAMP (Linear Affine Mixing of Parametric shapes), a data-efficient framework for controllable and interpretable 3D generation. LAMP first aligns signed distance function (SDF) decoders by overfitting each exemplar from a shared initialization, then synthesizes new geometries by solving a parameter-constrained mixing problem in the aligned weight space. To ensure robustness, we further propose a safety metric that detects geometry validity via linearity mismatch. We evaluate LAMP on two 3D parametric benchmarks: DrivAerNet++ and BlendedNet. We found that LAMP enables (i) controlled interpolation within bounds with as few as 100 samples, (ii) safe extrapolation by up to 100% parameter difference beyond training ranges, (iii) physics performance-guided optimization under fixed parameters. LAMP significantly outperforms conditional autoencoder and Deep Network Interpolation (DNI) baselines in both extrapolation and data efficiency. Our results demonstrate that LAMP advances controllable, data-efficient, and safe 3D generation for design exploration, dataset generation, and performance-driven optimization.",2510.22491v1,http://arxiv.org/abs/2510.22491v1
DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss,"Jing Yang, Yufeng Yang",2025-10-26,"Recent advancements in 2D and 3D generative models have expanded the capabilities of computer vision. However, generating high-quality 4D dynamic content from a single static image remains a significant challenge. Traditional methods have limitations in modeling temporal dependencies and accurately capturing dynamic geometry changes, especially when considering variations in camera perspective. To address this issue, we propose DynaPose4D, an innovative solution that integrates 4D Gaussian Splatting (4DGS) techniques with Category-Agnostic Pose Estimation (CAPE) technology. This framework uses 3D Gaussian Splatting to construct a 3D model from single images, then predicts multi-view pose keypoints based on one-shot support from a chosen view, leveraging supervisory signals to enhance motion consistency. Experimental results show that DynaPose4D achieves excellent coherence, consistency, and fluidity in dynamic motion generation. These findings not only validate the efficacy of the DynaPose4D framework but also indicate its potential applications in the domains of computer vision and animation production.",2510.22473v1,http://arxiv.org/abs/2510.22473v1
Data-driven Augmentation of Turbulence Model in Three-dimensional Flows Via Sequential Correction,"Chenyu Wu, Shaoguang Zhang, Yufei Zhang",2025-10-26,"Classic turbulence models often struggle to accurately predict complex flows that involve phenomena such as flow separation. Although data-driven techniques have emerged to address these shortcomings by augmenting classical models with correction terms, most existing research has concentrated on two-dimensional (2D) cases. Therefore, the performance of these corrected models in complex three-dimensional (3D) flows remains an underexplored area. This study addresses this gap by enhancing a data-driven turbulence model, the SST-CND (shear stress transport-conditioned) model, which was originally trained on 2D separated flows. An additional correction term, \b{eta}_3D, is introduced to account for 3D effects. The distribution of this term is initially determined through a 3D field inversion process using high-fidelity data obtained from the flow around a cube. An explicit algebraic expression for \b{eta}_3D is then derived through symbolic regression and formulated to degrade to zero in 2D cases. This new expression is integrated into the original model, resulting in the SST-CND3D model. The performance of the SST-CND3D model is evaluated across a range of flows. In 2D flows, including the separated flow around a hump, flow over a flat plate, and flow around a multi-element airfoil, the SST-CND3D model performs identically to its 2D-trained predecessor. However, the model exhibits superior performance in 3D flows, such as the flow around a cube and the complex, real-world JAXA standard model high-lift configuration. These findings indicate that a sequential correction approach, constructing a 3D correction term that vanishes in 2D on top of a 2D-trained model, constitutes a promising method for developing data-driven turbulence models that maintain accuracy in 3D while preserving their effectiveness in 2D.",2510.22469v1,http://arxiv.org/abs/2510.22469v1
SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning,"Linhan Wang, Jianwen Dou, Wang Li, Shengkun Wang, Zhiwu Xie, Chang-Tien Lu, Yinlin Chen",2025-10-25,"Cryogenic Electron Tomography (CryoET) combined with sub-volume averaging (SVA) is the only imaging modality capable of resolving protein structures inside cells at molecular resolution. Particle picking, the task of localizing and classifying target proteins in 3D CryoET volumes, remains the main bottleneck. Due to the reliance on time-consuming manual labels, the vast reserve of unlabeled tomograms remains underutilized. In this work, we present a fast, label-efficient semi-supervised framework that exploits this untapped data. Our framework consists of two components: (i) an end-to-end heatmap-supervised detection model inspired by keypoint detection, and (ii) a teacher-student co-training mechanism that enhances performance under sparse labeling conditions. Furthermore, we introduce multi-view pseudo-labeling and a CryoET-specific DropBlock augmentation strategy to further boost performance. Extensive evaluations on the large-scale CZII dataset show that our approach improves F1 by 10% over supervised baselines, underscoring the promise of semi-supervised learning for leveraging unlabeled CryoET data.",2510.22454v1,http://arxiv.org/abs/2510.22454v1
3D Roadway Scene Object Detection with LIDARs in Snowfall Conditions,"Ghazal Farhani, Taufiq Rahman, Syed Mostaquim Ali, Andrew Liu, Mohamed Zaki, Dominique Charlebois, Benoit Anctil",2025-10-25,"Because 3D structure of a roadway environment can be characterized directly by a Light Detection and Ranging (LiDAR) sensors, they can be used to obtain exceptional situational awareness for assitive and autonomous driving systems. Although LiDARs demonstrate good performance in clean and clear weather conditions, their performance significantly deteriorates in adverse weather conditions such as those involving atmospheric precipitation. This may render perception capabilities of autonomous systems that use LiDAR data in learning based models to perform object detection and ranging ineffective. While efforts have been made to enhance the accuracy of these models, the extent of signal degradation under various weather conditions remains largely not quantified. In this study, we focus on the performance of an automotive grade LiDAR in snowy conditions in order to develop a physics-based model that examines failure modes of a LiDAR sensor. Specifically, we investigated how the LiDAR signal attenuates with different snowfall rates and how snow particles near the source serve as small but efficient reflectors. Utilizing our model, we transform data from clear conditions to simulate snowy scenarios, enabling a comparison of our synthetic data with actual snowy conditions. Furthermore, we employ this synthetic data, representative of different snowfall rates, to explore the impact on a pre-trained object detection model, assessing its performance under varying levels of snowfall",2510.22436v1,http://arxiv.org/abs/2510.22436v1
SHELLQs-JWST: Revealing the Spectra of Extended Emission in 12 z > 6 Quasar Host Galaxies using the JWST NIRSpec Fixed Slit,"Camryn L. Phillips, Michael A. Strauss, Masafusa Onoue, Xuheng Ding, John D. Silverman, Yoshiki Matsuoka, Takuma Izumi, Junya Arita, Kentaro Aoki, Shunsuke Baba, Masatoshi Imanishi, Nobunari Kashikawa, Toshihiro Kawaguchi, Chien-Hsiu Lee, Mahoshi Sawamura, Yoshiki Toba, Feige Wang, Jinyi Yang",2025-10-25,"We present an analysis of the rest frame optical JWST NIRSpec Fixed Slit spectra of extended host galaxy emission in 12 quasars from the Subaru High-z Exploration of Low-Luminosity Quasars (SHELLQs) sample at redshifts 6.0 < z < 6.4. The spatial point spread function is modeled primarily by a sum of two Gaussians as a function of wavelength and is used to fit and subtract the quasar from the 2D spectra, leaving only extended galaxy emission which we analyze. Ten of 12 systems show spatially extended line emission and five of 12 systems show an extended stellar continuum. From the extended [OIII]5008 emission line, we measure a 132 ${\pm}$ 19 km/s ionized outflow in one system and 52 ${\pm}$ 12 km/s rotation, suggesting a coherent disk, in another. From the extended narrow H${\alpha}$ emission, which we hypothesize is ionized by star-forming regions rather than the quasar, we measure star formation rates ranging from ${\sim}$ 7 to 111 M${_\odot}$/yr, the majority of which are consistent with the star-forming main sequence at z ${\approx}$ 6. The positions of our host galaxies on the log10[OIII]5008/H${\beta}$ vs. log10[NII]6584/H${\alpha}$ (R3N2) Baldwin-Phillips-Terlevich (BPT) diagram indicate ionization rates typical of AGN activity in the low-redshift universe, but are consistent with the placement of similar z ${\approx}$ 6 quasar host galaxies, suggesting that the R3N2 line ratios cannot distinguish AGN and star-formation powered line emission at high redshifts. We conclude from the consistency between our quasar host sample with z ${\sim}$ 6 galaxies that the presence of a low-luminosity AGN causes little significant change in the properties of galaxies at z ${\approx}$ 6 on 10 Myr timescales.",2510.22403v1,http://arxiv.org/abs/2510.22403v1
A Fully Interpretable Statistical Approach for Roadside LiDAR Background Subtraction,"Aitor Iglesias, Nerea Aranjuelo, Patricia Javierre, Ainhoa Menendez, Ignacio Arganda-Carreras, Marcos Nieto",2025-10-25,"We present a fully interpretable and flexible statistical method for background subtraction in roadside LiDAR data, aimed at enhancing infrastructure-based perception in automated driving. Our approach introduces both a Gaussian distribution grid (GDG), which models the spatial statistics of the background using background-only scans, and a filtering algorithm that uses this representation to classify LiDAR points as foreground or background. The method supports diverse LiDAR types, including multiline 360 degree and micro-electro-mechanical systems (MEMS) sensors, and adapts to various configurations. Evaluated on the publicly available RCooper dataset, it outperforms state-of-the-art techniques in accuracy and flexibility, even with minimal background data. Its efficient implementation ensures reliable performance on low-resource hardware, enabling scalable real-world deployment.",2510.22390v1,http://arxiv.org/abs/2510.22390v1
Privacy-Aware Federated nnU-Net for ECG Page Digitization,Nader Nemati,2025-10-25,"Deep neural networks can convert ECG page images into analyzable waveforms, yet centralized training often conflicts with cross-institutional privacy and deployment constraints. A cross-silo federated digitization framework is presented that trains a full-model nnU-Net segmentation backbone without sharing images and aggregates updates across sites under realistic non-IID heterogeneity (layout, grid style, scanner profile, noise).   The protocol integrates three standard server-side aggregators--FedAvg, FedProx, and FedAdam--and couples secure aggregation with central, user-level differential privacy to align utility with formal guarantees. Key features include: (i) end-to-end full-model training and synchronization across clients; (ii) secure aggregation so the server only observes a clipped, weighted sum once a participation threshold is met; (iii) central Gaussian DP with Renyi accounting applied post-aggregation for auditable user-level privacy; and (iv) a calibration-aware digitization pipeline comprising page normalization, trace segmentation, grid-leakage suppression, and vectorization to twelve-lead signals.   Experiments on ECG pages rendered from PTB-XL show consistently faster convergence and higher late-round plateaus with adaptive server updates (FedAdam) relative to FedAvg and FedProx, while approaching centralized performance. The privacy mechanism maintains competitive accuracy while preventing exposure of raw images or per-client updates, yielding deployable, auditable guarantees suitable for multi-institution settings.",2510.22387v1,http://arxiv.org/abs/2510.22387v1
Instability and vertical eccentricity variation in global hydrodynamic disk simulations,"Janosz W. Dewberry, Henrik N. Latter, Gordon I. Ogilvie, Sebastien Fromang",2025-10-25,"Many dynamical interactions can induce eccentricities in astrophysical accretion disks. Disk eccentricities in turn seed a variety of instabilities, even in ideal hydrodynamics. We use 3D nonlinear simulations and 2+1D linear calculations to characterize local and global instabilities in strongly distorted disks. On local scales, our simulations show the growth of parametrically excited inertial waves, which drive wave turbulence. The inertial waves' growth rates and localizations agree with the predictions of local theory. On global scales, we observe the growth of a separate family of low-frequency, vertically structured modes that compare favorably with eigenmodes computed from the linear theory of an eccentric background state. These low-frequency modes interact nonlinearly with the inertial wave turbulence driven by parametric instability, and they induce variation in eccentricity profiles that are initially uniform in the vertical direction. Extrapolating from our vertically local framework, we postulate that these secondary distortions may correspond to the corrugation of an initially planar eccentric disk. Our simulations demonstrate that strong disk eccentricities drive numerous dynamical phenomena even in a purely hydrodynamic, Newtonian framework.",2510.22381v1,http://arxiv.org/abs/2510.22381v1
T2SMark: Balancing Robustness and Diversity in Noise-as-Watermark for Diffusion Models,"Jindong Yang, Han Fang, Weiming Zhang, Nenghai Yu, Kejiang Chen",2025-10-25,"Diffusion models have advanced rapidly in recent years, producing high-fidelity images while raising concerns about intellectual property protection and the misuse of generative AI. Image watermarking for diffusion models, particularly Noise-as-Watermark (NaW) methods, encode watermark as specific standard Gaussian noise vector for image generation, embedding the infomation seamlessly while maintaining image quality. For detection, the generation process is inverted to recover the initial noise vector containing the watermark before extraction. However, existing NaW methods struggle to balance watermark robustness with generation diversity. Some methods achieve strong robustness by heavily constraining initial noise sampling, which degrades user experience, while others preserve diversity but prove too fragile for real-world deployment. To address this issue, we propose T2SMark, a two-stage watermarking scheme based on Tail-Truncated Sampling (TTS). Unlike prior methods that simply map bits to positive or negative values, TTS enhances robustness by embedding bits exclusively in the reliable tail regions while randomly sampling the central zone to preserve the latent distribution. Our two-stage framework then ensures sampling diversity by integrating a randomly generated session key into both encryption pipelines. We evaluate T2SMark on diffusion models with both U-Net and DiT backbones. Extensive experiments show that it achieves an optimal balance between robustness and diversity. Our code is available at \href{https://github.com/0xD009/T2SMark}{https://github.com/0xD009/T2SMark}.",2510.22366v1,http://arxiv.org/abs/2510.22366v1
EndoSfM3D: Learning to 3D Reconstruct Any Endoscopic Surgery Scene using Self-supervised Foundation Model,"Changhao Zhang, Matthew J. Clarkson, Mobarak I. Hoque",2025-10-25,"3D reconstruction of endoscopic surgery scenes plays a vital role in enhancing scene perception, enabling AR visualization, and supporting context-aware decision-making in image-guided surgery. A critical yet challenging step in this process is the accurate estimation of the endoscope's intrinsic parameters. In real surgical settings, intrinsic calibration is hindered by sterility constraints and the use of specialized endoscopes with continuous zoom and telescope rotation. Most existing methods for endoscopic 3D reconstruction do not estimate intrinsic parameters, limiting their effectiveness for accurate and reliable reconstruction. In this paper, we integrate intrinsic parameter estimation into a self-supervised monocular depth estimation framework by adapting the Depth Anything V2 (DA2) model for joint depth, pose, and intrinsics prediction. We introduce an attention-based pose network and a Weight-Decomposed Low-Rank Adaptation (DoRA) strategy for efficient fine-tuning of DA2. Our method is validated on the SCARED and C3VD public datasets, demonstrating superior performance compared to recent state-of-the-art approaches in self-supervised monocular depth estimation and 3D reconstruction. Code and model weights can be found in project repository: https://github.com/MOYF-beta/EndoSfM3D.",2510.22359v1,http://arxiv.org/abs/2510.22359v1
Uncertainty quantification in model discovery by distilling interpretable material constitutive models from Gaussian process posteriors,"David Anton, Henning Wessels, Ulrich Römer, Alexander Henkes, Jorge-Humberto Urrea-Quintero",2025-10-25,"Constitutive model discovery refers to the task of identifying an appropriate model structure, usually from a predefined model library, while simultaneously inferring its material parameters. The data used for model discovery are measured in mechanical tests and are thus inevitably affected by noise which, in turn, induces uncertainties. Previously proposed methods for uncertainty quantification in model discovery either require the selection of a prior for the material parameters, are restricted to the linear coefficients of the model library or are limited in the flexibility of the inferred parameter probability distribution. We therefore propose a four-step partially Bayesian framework for uncertainty quantification in model discovery that does not require prior selection for the material parameters and also allows for the discovery of non-linear constitutive models: First, we augment the available stress-deformation data with a Gaussian process. Second, we approximate the parameter distribution by a normalizing flow, which allows for capturing complex joint distributions. Third, we distill the parameter distribution by matching the distribution of stress-deformation functions induced by the parameters with the Gaussian process posterior. Fourth, we perform a Sobol' sensitivity analysis to obtain a sparse and interpretable model. We demonstrate the capability of our framework for both isotropic and anisotropic experimental data as well as linear and non-linear model libraries.",2510.22345v1,http://arxiv.org/abs/2510.22345v1
Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks,"Enyi Wang, Zhen Deng, Chuanchuan Pan, Bingwei He, Jianwei Zhang",2025-10-25,"This paper presents a learning-based approach for accurately estimating the 3D shape of flexible continuum robots subjected to external loads. The proposed method introduces a spatiotemporal neural network architecture that fuses multi-modal inputs, including current and historical tendon displacement data and RGB images, to generate point clouds representing the robot's deformed configuration. The network integrates a recurrent neural module for temporal feature extraction, an encoding module for spatial feature extraction, and a multi-modal fusion module to combine spatial features extracted from visual data with temporal dependencies from historical actuator inputs. Continuous 3D shape reconstruction is achieved by fitting B\'ezier curves to the predicted point clouds. Experimental validation demonstrates that our approach achieves high precision, with mean shape estimation errors of 0.08 mm (unloaded) and 0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for TDCRs. The results validate the efficacy of deep learning-based spatiotemporal data fusion for precise shape estimation under loading conditions.",2510.22339v1,http://arxiv.org/abs/2510.22339v1
GeoDiffusion: A Training-Free Framework for Accurate 3D Geometric Conditioning in Image Generation,"Phillip Mueller, Talip Uenlue, Sebastian Schmidt, Marcel Kollovieh, Jiajie Fan, Stephan Guennemann, Lars Mikelsons",2025-10-25,"Precise geometric control in image generation is essential for engineering \& product design and creative industries to control 3D object features accurately in image space. Traditional 3D editing approaches are time-consuming and demand specialized skills, while current image-based generative methods lack accuracy in geometric conditioning. To address these challenges, we propose GeoDiffusion, a training-free framework for accurate and efficient geometric conditioning of 3D features in image generation. GeoDiffusion employs a class-specific 3D object as a geometric prior to define keypoints and parametric correlations in 3D space. We ensure viewpoint consistency through a rendered image of a reference 3D object, followed by style transfer to meet user-defined appearance specifications. At the core of our framework is GeoDrag, improving accuracy and speed of drag-based image editing on geometry guidance tasks and general instructions on DragBench. Our results demonstrate that GeoDiffusion enables precise geometric modifications across various iterative design workflows.",2510.22337v1,http://arxiv.org/abs/2510.22337v1
Enhanced magnetic and optical properties of oxygen deficient TiO$_{2-δ}$ nanoparticles synthesized by environment-friendly green route using whole plant extract of Phyllanthus niruri,"Latika Mishra, Vinod Kumar Dwivedi, Vishal Kumar Chakradhary, Akila G. Prabhudessai, Shamshun Nehar",2025-10-25,"We report magnetic, optical and oxidation states of oxygen deficient TiO$_{2-\delta}$ nanoparticles (NPs) synthesized by environment-friendly green route using Phyllanthus niruri (PN) whole plant extract instead of leaf extract. Rietveld refinement of room temperature XRD pattern confirms the formation of pure phase anatase TiO$_2$ crystals in a tetragonal structure with space group I41/amd. TEM and SEM microstructure shows agglomerated spherical shape NPs exhibiting average particle size $\sim$ 35~nm. FTIR result confirms the presence of biomolecules and functional group attached to the surface of TiO$_2$ NPs. The core level XPS of O-1s and Ti-2p confirms the presence of oxygen vacancies that leads to the mixed oxidation states of Ti (Ti$^{4+}$ and Ti$^{3+}$). UV-vis result shows a strong absorption peak ($\sim$ 250~nm) along with reduced optical band gap energy E$_g$ $\sim$ 2.75~eV, possibly arises due to the surface plasmon resonance (SPR) caused by lower band gap energy emerging from oxygen vacancies. Magnetization as a function of applied magnetic field shows ferromagnetic nature at room temperature [M$_S$ $\sim$ 0.029~emu/g and H$_C$ $\sim$ 0.0143~T]. The observed ferromagnetic behaviour can be understood by virtual hopping of electrons from Ti$^{3+}$(3d$^1$) to Ti$^{4+}$(3d$^0$)-sites, however, vice versa is prohibited.",2510.22296v1,http://arxiv.org/abs/2510.22296v1
"Analyzing GW231109_235456 and understanding its potential implications for population studies, nuclear physics, and multi-messenger astronomy","Thibeau Wouters, Anna Puecher, Peter T. H. Pang, Tim Dietrich",2025-10-25,"We study the gravitational-wave trigger GW231109_235456, a sub-threshold binary neutron star merger candidate observed in the first part of the fourth observing run of the LIGO-Virgo-KAGRA collaboration. Assuming the trigger is of astrophysical origin, we analyze it using state-of-the-art waveform models and investigate the robustness of the inferred source parameters under different prior choices in Bayesian inference. We assess the implications for population studies, nuclear physics, and multi-messenger astronomy. Analysing the component masses, we find that GW231109_235456 supports the proposed double Gaussian mass distribution of neutron star masses. Moreover, we find that the remnant most likely collapsed promptly to a black hole and that, because of the large distance, a possible kilonova connected to the merger was noticeably dimmer than AT2017gfo. In addition, we provide constraints on the equation of state from GW231109_235456 alone, as well as combined with GW170817 and GW190425. In our projections for the future, we simulate a similar event using the upcoming generation of gravitational-wave detectors. Our findings indicate that we can constrain the neutron star radius with an accuracy of 400 meters using the Einstein Telescope alone, or 300 meters when combined with the Cosmic Explorer, both at 90% credibility.",2510.22290v1,http://arxiv.org/abs/2510.22290v1
SecureLearn - An Attack-agnostic Defense for Multiclass Machine Learning Against Data Poisoning Attacks,"Anum Paracha, Junaid Arshad, Mohamed Ben Farah, Khalid Ismail",2025-10-25,"Data poisoning attacks are a potential threat to machine learning (ML) models, aiming to manipulate training datasets to disrupt their performance. Existing defenses are mostly designed to mitigate specific poisoning attacks or are aligned with particular ML algorithms. Furthermore, most defenses are developed to secure deep neural networks or binary classifiers. However, traditional multiclass classifiers need attention to be secure from data poisoning attacks, as these models are significant in developing multi-modal applications. Therefore, this paper proposes SecureLearn, a two-layer attack-agnostic defense to defend multiclass models from poisoning attacks. It comprises two components of data sanitization and a new feature-oriented adversarial training. To ascertain the effectiveness of SecureLearn, we proposed a 3D evaluation matrix with three orthogonal dimensions: data poisoning attack, data sanitization and adversarial training. Benchmarking SecureLearn in a 3D matrix, a detailed analysis is conducted at different poisoning levels (10%-20%), particularly analysing accuracy, recall, F1-score, detection and correction rates, and false discovery rate. The experimentation is conducted for four ML algorithms, namely Random Forest (RF), Decision Tree (DT), Gaussian Naive Bayes (GNB) and Multilayer Perceptron (MLP), trained with three public datasets, against three poisoning attacks and compared with two existing mitigations. Our results highlight that SecureLearn is effective against the provided attacks. SecureLearn has strengthened resilience and adversarial robustness of traditional multiclass models and neural networks, confirming its generalization beyond algorithm-specific defenses. It consistently maintained accuracy above 90%, recall and F1-score above 75%. For neural networks, SecureLearn achieved 97% recall and F1-score against all selected poisoning attacks.",2510.22274v1,http://arxiv.org/abs/2510.22274v1
DiffusionLane: Diffusion Model for Lane Detection,"Kunyang Zhou, Yeqin Shao",2025-10-25,"In this paper, we present a novel diffusion-based model for lane detection, called DiffusionLane, which treats the lane detection task as a denoising diffusion process in the parameter space of the lane. Firstly, we add the Gaussian noise to the parameters (the starting point and the angle) of ground truth lanes to obtain noisy lane anchors, and the model learns to refine the noisy lane anchors in a progressive way to obtain the target lanes. Secondly, we propose a hybrid decoding strategy to address the poor feature representation of the encoder, resulting from the noisy lane anchors. Specifically, we design a hybrid diffusion decoder to combine global-level and local-level decoders for high-quality lane anchors. Then, to improve the feature representation of the encoder, we employ an auxiliary head in the training stage to adopt the learnable lane anchors for enriching the supervision on the encoder. Experimental results on four benchmarks, Carlane, Tusimple, CULane, and LLAMAS, show that DiffusionLane possesses a strong generalization ability and promising detection performance compared to the previous state-of-the-art methods. For example, DiffusionLane with ResNet18 surpasses the existing methods by at least 1\% accuracy on the domain adaptation dataset Carlane. Besides, DiffusionLane with MobileNetV4 gets 81.32\% F1 score on CULane, 96.89\% accuracy on Tusimple with ResNet34, and 97.59\% F1 score on LLAMAS with ResNet101. Code will be available at https://github.com/zkyntu/UnLanedet.",2510.22236v1,http://arxiv.org/abs/2510.22236v1
